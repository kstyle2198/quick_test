{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec1fd45-58c9-40e7-841c-6798c5f5b086",
   "metadata": {},
   "source": [
    "# LLM Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd0188-2cb5-426d-8163-7c47335cf437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key=os.environ.get(\"openrouter_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcfb068-a845-4993-975b-ae2487d56ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(\n",
    "#     model = \"qwen/qwen3-14b:free\", # \"qwen/qwen3-14b:free\", \"qwen/qwen3-30b-a3b:free\",\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=api_key,\n",
    "#     )\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\", temperature=0, max_tokens=8000,) # \"gemma2-9b-it\", qwen-qwq-32b \"llama-3.3-70b-versatile\"  llama-3.1-8b-instant\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# llm = ChatOpenAI(\n",
    "#     model = \"qwen3:4b\",\n",
    "#     base_url=\"http://localhost:11434/v1\",\n",
    "#     api_key=\"ollama\",\n",
    "# )\n",
    "\n",
    "llm.invoke(\"안녕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed9e713-e636-485a-9b7d-2652f280c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "reranking_model_path = \"D:/LLMs/bge-reranker-v2-m3\"\n",
    "reranker = FlagReranker(model_name_or_path=reranking_model_path, \n",
    "                        use_fp16=True,\n",
    "                        batch_size=512,\n",
    "                        max_length=2048,\n",
    "                        normalize=True)\n",
    "reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc788b86-8a07-4edc-a5a2-c45a8bb1afb7",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17efeb9a-5c8a-429e-a86e-3f91aaec140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_planner_query_writer_instructions=\"\"\"당신은 안전관리 보고서를 위한 조사를 수행하고 있습니다.. \n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Report organization>\n",
    "{report_organization}\n",
    "</Report organization>\n",
    "\n",
    "<Task>\n",
    "당신의 목표는 보고서의 각 섹션을 계획하는 데 도움이 될 수 있는 웹 검색 쿼리 {number_of_queries}개를 생성하는 것입니다.\n",
    "생성된 쿼리는 다음 조건을 만족해야 합니다:\n",
    "\n",
    "    - 보고서 주제와 관련이 있어야 합니다.\n",
    "    - 보고서 구성에 명시된 요구사항을 충족하는 데 도움이 되어야 합니다.\n",
    "\n",
    "검색 쿼리는 고품질의 관련 자료를 찾을 수 있을 정도로 구체적이어야 하며, 동시에 보고서 구조 전반을 아우를 수 있도록 폭넓게 다루어야 합니다.\n",
    "</Task>\n",
    "\n",
    "<Format>\n",
    "Queries 도구를 호출하세요\n",
    "</Format>\n",
    "\"\"\"\n",
    "\n",
    "report_structure = \"\"\"다음 구조를 사용하여 사용자가 제공한 주제에 대한 보고서를 작성하세요:\n",
    "\n",
    "1. 서론 (조사 불필요)\n",
    "    주제 영역에 대한 간략한 개요\n",
    "\n",
    "2. 본론\n",
    "    각 본론 항목은 사용자가 제공한 주제의 하위 주제에 초점을 맞춰야 함\n",
    "\n",
    "3. 결론\n",
    "    본론 내용을 요약하는 구조적 요소 1개 포함 (목록 또는 표 중 하나)\n",
    "    보고서의 간결한 요약 제공\"\"\"\n",
    "\n",
    "report_planner_instructions=\"\"\"간결하고 핵심에 집중된 보고서 계획을 원합니다.\n",
    "\n",
    "<Report topic>\n",
    "보고서의 주제는 다음과 같습니다:\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Report organization>\n",
    "보고서는 다음과 같은 구성에 따라야 합니다:\n",
    "{report_organization}\n",
    "</Report organization>\n",
    "\n",
    "<Context>\n",
    "보고서의 섹션을 계획할 때 사용할 문맥은 다음과 같습니다:\n",
    "{context}\n",
    "</Context>\n",
    "\n",
    "<Task>\n",
    "보고서의 섹션 목록을 작성하세요. 계획은 명확하고 집중되어야 하며, 겹치는 섹션이나 불필요한 내용은 없어야 합니다.\n",
    "\n",
    "예를 들어, 좋은 보고서 구조는 다음과 같을 수 있습니다:\n",
    "1/ 서론\n",
    "2/ 주제 A 개요\n",
    "3/ 주제 B 개요\n",
    "4/ A와 B의 비교\n",
    "5/ 결론\n",
    "\n",
    "각 섹션은 다음 항목을 포함해야 합니다:\n",
    "\n",
    "    - 이름 : 해당 보고서 섹션의 이름\n",
    "    - 설명 : 이 섹션에서 다룰 주요 주제에 대한 간략한 개요\n",
    "    - 조사 : 이 섹션을 위해 웹 조사가 필요한지 여부. 중요: 본문 섹션(서론/결론 제외)은 반드시 조사=True 이어야 함. 보고서는 유용하려면 최소 2~3개의 조사=True 섹션이 있어야 함.\n",
    "    - 내용 : 섹션의 실제 내용. 지금은 비워둠\n",
    "\n",
    "통합 지침:\n",
    "\n",
    "    - 예시와 구현 세부사항은 별도 섹션이 아니라 주요 주제 섹션 내에 포함할 것\n",
    "    - 각 섹션은 명확히 구분되는 목적을 가져야 하며, 내용이 중복되지 않아야 함\n",
    "    - 관련 개념은 분리하지 말고 통합할 것\n",
    "    - 매우 중요: 모든 섹션은 반드시 주제와 직접적인 관련이 있어야 함\n",
    "    - 주제와 직접 연결되지 않은 주변적인 내용이나 느슨하게 관련된 섹션은 피할 것\n",
    "\n",
    "제출 전에 구조를 검토하여 중복되는 섹션이 없고 논리적인 흐름을 따르는지 확인하세요.\n",
    "</Task>\n",
    "\n",
    "<Feedback>\n",
    "검토 과정에서 받은 보고서 구조에 대한 피드백이 있다면 다음과 같습니다:\n",
    "{feedback}\n",
    "</Feedback>\n",
    "\n",
    "<Format>\n",
    "Sections 도구를 호출하세요.\n",
    "</Format>\n",
    "\"\"\"\n",
    "\n",
    "planner_message = \"\"\"보고서의 섹션을 생성합니다. 응답에는 섹션 목록이 포함된 '섹션' 필드가 포함되어야 합니다.\n",
    "각 섹션에는 이름, 설명, 계획, 연구 및 콘텐츠 필드가 있어야 합니다.\"\"\"\n",
    "\n",
    "query_writer_instructions=\"\"\"당신은 안전관리 기술 보고서의 한 섹션을 작성하기 위해 포괄적인 정보를 수집할 수 있는 웹 검색 쿼리를 생성하는 안전관리 전문가 입니다.\n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Section topic>\n",
    "{section_topic}\n",
    "</Section topic>\n",
    "\n",
    "<Task>\n",
    "당신의 목표는 위의 섹션 주제에 대한 포괄적인 정보를 수집하는 데 도움이 되는 검색 쿼리 {number_of_queries}개를 생성하는 것입니다.\n",
    "\n",
    "검색 쿼리는 다음 기준을 충족해야 합니다:\n",
    "\n",
    "    1. 주제와 관련이 있어야 합니다\n",
    "    2. 주제의 다양한 측면을 조사해야 합니다\n",
    "\n",
    "쿼리는 고품질의 관련 있는 자료를 찾을 수 있을 만큼 구체적이어야 합니다.\n",
    "</Task>\n",
    "\n",
    "<Format>\n",
    "Queries 도구를 호출하십시오\n",
    "</Format>\n",
    "\"\"\"\n",
    "\n",
    "section_writer_instructions = \"\"\"안전관리 관련 연구 보고서의 한 부분이 되는 섹션을 작성하십시오.\n",
    "\n",
    "<Task>\n",
    "1. 보고서 주제, 섹션 이름, 섹션 주제를 주의 깊게 검토하십시오.\n",
    "2. 기존 섹션 내용이 있다면 이를 검토하십시오.\n",
    "3. 제공된 자료(Source material)를 확인하십시오.\n",
    "4. 보고서 섹션 작성을 위해 사용할 자료를 결정하십시오.\n",
    "5. 보고서 섹션을 작성하고 사용한 출처를 나열하십시오.\n",
    "</Task>\n",
    "\n",
    "<Writing Guidelines>\n",
    "- 기존 섹션 내용이 비어 있다면 새로 작성하십시오.\n",
    "- 기존 섹션 내용이 있을 경우, 제공된 자료와 통합하여 작성하십시오.\n",
    "- 분량은 반드시 300~500단어 이내로 제한하십시오.\n",
    "- 문장은 간단하고 명확하게 작성하십시오.\n",
    "- 제공된 자료에 사례가 포함된 경우, 사례의 내용을 최대한 많이 포함해주세요.\n",
    "- 각 문장의 끝에 근거 문서의 정보를 표기해주세요.(파일제목 및 페이지 번호 등)\n",
    "- 단락은 짧게 유지하십시오 (최대 7문장).\n",
    "- 섹션 제목은 Markdown 형식으로 ##를 사용하십시오.\n",
    "- 섹션 제목을 반복하지 마세요.\n",
    "</Writing Guidelines>\n",
    "\n",
    "<Citation Rules>\n",
    "- 섹션 내용 작성에 직접적으로 관련된 각 고유한 filename에 하나의 인용 번호를 부여하십시오.\n",
    "- 섹션 끝에는 ### 출처라는 제목 아래 출처 목록을 작성하십시오.\n",
    "- 중요: 어떤 자료를 선택했든, 최종 목록의 출처 번호는 반드시 빠짐없이 순차적으로 매겨야 합니다.\n",
    "\n",
    "- 예시 형식:\n",
    "  [1] 파일 제목 (Page 번호)\n",
    "  [2] 파일 제목  (Page 번호)\n",
    "</Citation Rules>\n",
    "\n",
    "<Final Check>\n",
    "1. 모든 주장들이 제공된 자료에 기반하고 있는지 확인하십시오.\n",
    "2. 각 filename이 출처 목록에 단 한 번만 나타나는지 확인하십시오.\n",
    "3. 출처 번호가 빠짐없이 순차적으로 매겨졌는지 확인하십시오.\n",
    "</Final Check>\n",
    "\"\"\"\n",
    "\n",
    "section_writer_inputs=\"\"\" \n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Section name>\n",
    "{section_name}\n",
    "</Section name>\n",
    "\n",
    "<Section topic>\n",
    "{section_topic}\n",
    "</Section topic>\n",
    "\n",
    "<Existing section content (if populated)>\n",
    "{section_content}\n",
    "</Existing section content>\n",
    "\n",
    "<Source material>\n",
    "{context}\n",
    "</Source material>\n",
    "\"\"\"\n",
    "\n",
    "section_grader_instructions = \"\"\"보고서의 특정 주제에 해당하는 섹션을 검토하세요:\n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<section topic>\n",
    "{section_topic}\n",
    "</section topic>\n",
    "\n",
    "<section content>\n",
    "{section}\n",
    "</section content>\n",
    "\n",
    "<task>\n",
    "섹션 내용이 섹션 주제를 충분히 다루고 있는지 평가하세요.\n",
    "섹션 내용이 섹션 주제를 충분히 다루지 못한 경우, 부족한 정보를 수집하기 위한 검색 질의 {number_of_follow_up_queries}개를 생성하세요.\n",
    "</task>\n",
    "\n",
    "<format>\n",
    "Feedback 도구를 호출하고 다음 스키마에 따라 출력하세요:\n",
    "\n",
    "grade: Literal[\"pass\",\"fail\"] = Field(\n",
    "    설명=\"응답이 요구사항을 충족하는지('pass') 또는 수정이 필요한지('fail')를 나타내는 평가 결과.\"\n",
    ")\n",
    "follow_up_queries: List[SearchQuery] = Field(\n",
    "    설명=\"후속 검색 질의 목록.\"\n",
    ")\n",
    "</format>\n",
    "\"\"\"\n",
    "\n",
    "final_section_writer_instructions=\"\"\"당신은 보고서의 나머지 내용을 종합하여 하나의 섹션으로 작성하는 안전관리 전문 기술 작가입니다.\n",
    "\n",
    "<Report topic>\n",
    "{topic}\n",
    "</Report topic>\n",
    "\n",
    "<Section name>\n",
    "{section_name}\n",
    "</Section name>\n",
    "\n",
    "<Section topic> \n",
    "{section_topic}\n",
    "</Section topic>\n",
    "\n",
    "<Available report content>\n",
    "{context}\n",
    "</Available report content>\n",
    "\n",
    "<Task>\n",
    "1. 섹션별 접근 방식:\n",
    "\n",
    "도입부(Introduction)의 경우:\n",
    "\n",
    "    - 보고서 제목은 #을 사용해 작성 (Markdown 형식)\n",
    "    - 분량은 50~100단어\n",
    "    - 간단하고 명확한 언어 사용\n",
    "    - 보고서의 핵심 동기를 1~2단락으로 설명\n",
    "    - 명확한 서사 구조로 보고서를 소개\n",
    "    - 구조적 요소 사용 금지 (리스트, 표 등 포함하지 않음)\n",
    "    - 출처 섹션 불필요\n",
    "\n",
    "결론/요약(Conclusion/Summary)의 경우:\n",
    "\n",
    "    - 섹션 제목은 ##을 사용해 작성 (Markdown 형식)\n",
    "    - 분량은 100~150단어\n",
    "    - 비교 보고서의 경우:\n",
    "\n",
    "        * Markdown 표 문법을 사용해 핵심 비교 표를 반드시 포함\n",
    "        * 표는 보고서의 통찰을 간결하게 요약\n",
    "        * 표의 항목은 명확하고 간결하게 작성\n",
    "\n",
    "    - 비교 보고서가 아닐 경우:\n",
    "\n",
    "        * 보고서에서 제시된 내용을 요약하는 데 도움이 되는 구조적 요소를 하나만 사용\n",
    "        * 사용 가능한 구조:\n",
    "        \n",
    "            보고서의 항목을 비교하는 간단한 표 (Markdown 표 문법 사용)\n",
    "            짧은 리스트 (Markdown 리스트 문법 사용):\n",
    "                순서 없는 리스트: * 또는 - 사용\n",
    "                순서 있는 리스트: 1. 사용\n",
    "                들여쓰기 및 간격은 정확하게 유지\n",
    "\n",
    "    - 구체적인 다음 단계나 시사점으로 마무리\n",
    "    - 출처 섹션 불필요\n",
    "\n",
    "2. 작성 방식:\n",
    "- 일반적인 표현보다 구체적인 세부사항을 사용\n",
    "- 모든 단어에 의미를 부여\n",
    "- 가장 중요한 요점에 집중\n",
    "</Task>\n",
    "\n",
    "<Quality Checks>\n",
    "- 도입부 : 50-100 단어 사용, 레포트 타이틀에 # 사용, no structural elements, no sources section\n",
    "- 결론: 100-150 단어 사용, 섹현 타이틀에 ## 사용, only ONE structural element at most, no sources section\n",
    "- Markdown 형식\n",
    "- 단어 수나 서두는 포함하지 말 것\n",
    "</Quality Checks>\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198efd68-779b-4dae-b811-0784772a73d2",
   "metadata": {},
   "source": [
    "# Init Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26af572-402c-40eb-811c-1ab927a4e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_elasticsearch import ElasticsearchStore, DenseVectorStrategy\n",
    "\n",
    "def load_elastic_vectorstore(index_names: Union[str, List[str]]):\n",
    "    # 단일 문자열인 경우 리스트로 변환\n",
    "    if isinstance(index_names, str):\n",
    "        index_names = [index_names]\n",
    "    \n",
    "    vector_store = ElasticsearchStore(\n",
    "        index_name=index_names, \n",
    "        embedding=OllamaEmbeddings(\n",
    "            base_url=\"http://localhost:11434\", \n",
    "            model=\"bge-m3:latest\"\n",
    "        ), \n",
    "        es_url=\"http://localhost:9200\",\n",
    "        es_user=\"Kstyle\",\n",
    "        es_password=\"12345\",\n",
    "        )\n",
    "    return vector_store\n",
    "\n",
    "index_names = [\"ship_safety\"]\n",
    "vector_store = load_elastic_vectorstore(index_names=index_names)\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effba8f-8968-4b45-9c2b-4d443f378cf2",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474045f-64f4-4f10-b53a-6d44353fdbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, fields\n",
    "from typing import Any, Optional, Dict \n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Configuration:\n",
    "    \"\"\"The configurable fields for the chatbot.\"\"\"\n",
    "    # Common configuration\n",
    "    report_structure: str = report_structure # Defaults to the default report structure\n",
    "    search_api_config: Optional[Dict[str, Any]] = None\n",
    "    \n",
    "    # Graph-specific configuration\n",
    "    number_of_queries: int = 2 # Number of search queries to generate per iteration\n",
    "    max_search_depth: int = 2 # Maximum number of reflection + search iterations\n",
    "    \n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "        values: dict[str, Any] = {\n",
    "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
    "            for f in fields(cls)\n",
    "            if f.init\n",
    "        }\n",
    "        return cls(**{k: v for k, v in values.items() if v})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b767e969-aabb-4f12-88a1-da50e1467078",
   "metadata": {},
   "source": [
    "# States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffebe6c-79f6-47ff-82fb-a7ccb2900580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, TypedDict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import operator\n",
    "\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(description=\"Name for this section of the report.\",)\n",
    "    description: str = Field(description=\"Brief overview of the main topics and concepts to be covered in this section.\",)\n",
    "    research: bool = Field(description=\"Whether to perform web research for this section of the report.\")\n",
    "    content: str = Field(description=\"The content of the section.\")   \n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(description=\"Sections of the report.\",)\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Query for web search.\")\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[SearchQuery] = Field(description=\"List of search queries.\",)\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"pass\",\"fail\"] = Field(description=\"Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail').\")\n",
    "    follow_up_queries: List[SearchQuery] = Field(description=\"List of follow-up search queries.\",)\n",
    "\n",
    "class ReportStateInput(TypedDict):\n",
    "    topic: str # Report topic\n",
    "    index_names:list\n",
    "    k:int\n",
    "    \n",
    "class ReportStateOutput(TypedDict):\n",
    "    final_report: str # Final report\n",
    "\n",
    "class ReportState(TypedDict):\n",
    "    topic: str # Report topic    \n",
    "    feedback_on_report_plan: str # Feedback on the report plan\n",
    "    sections: list[Section] # List of report sections \n",
    "    completed_sections: Annotated[list, operator.add] # Send() API key\n",
    "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
    "    final_report: str # Final report\n",
    "    index_names:list\n",
    "    k:int\n",
    "\n",
    "class SectionState(TypedDict):\n",
    "    topic: str # Report topic\n",
    "    section: Section # Report section  \n",
    "    search_iterations: int # Number of search iterations done\n",
    "    search_queries: list[SearchQuery] # List of search queries\n",
    "    source_str: str # String of formatted source content from web search\n",
    "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
    "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
    "\n",
    "class SectionOutputState(TypedDict):\n",
    "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598efad9-2da5-4ad7-a3fb-640d292cc529",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a7838-7c75-4932-a76b-01ced7fb1d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sections(sections: list[Section]) -> str:\n",
    "    \"\"\" Format a list of sections into a string \"\"\"\n",
    "    formatted_str = \"\"\n",
    "    for idx, section in enumerate(sections, 1):\n",
    "        formatted_str += f\"\"\"\n",
    "{'='*60}\n",
    "Section {idx}: {section.name}\n",
    "{'='*60}\n",
    "Description:\n",
    "{section.description}\n",
    "Requires Research: \n",
    "{section.research}\n",
    "\n",
    "Content:\n",
    "{section.content if section.content else '[Not yet written]'}\n",
    "\n",
    "\"\"\"\n",
    "    return formatted_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab39df-d7fd-4a9e-82fc-3b0371deaf75",
   "metadata": {},
   "source": [
    "# Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b0aa42-355d-4402-afa2-28057a6da0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(queries:list):\n",
    "    retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={\"fetch_k\": 10, \"k\":5},)\n",
    "    documents = []\n",
    "    for query in queries:\n",
    "        docs = retriever.invoke(query)\n",
    "        documents.extend(docs)    \n",
    "    return documents\n",
    "\n",
    "import heapq\n",
    "def reranking(query: str, docs: list, min_score: float = 0.5, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    doc string\n",
    "    \"\"\"\n",
    "    global reranker\n",
    "    inputs = [[query, doc.page_content.lower()] for doc in docs]\n",
    "    scores = reranker.compute_score(inputs)\n",
    "    if not isinstance(scores, list):\n",
    "        scores = [scores]\n",
    "\n",
    "    print(f\">>> original scores: {scores}\")\n",
    "\n",
    "    # Filter scores by threshold and keep index\n",
    "    filtered_scores = [(score, idx) for idx, score in enumerate(scores) if score >= min_score]\n",
    "\n",
    "    # Get top_k using heapq (more efficient than sorting full list)\n",
    "    top_scores = heapq.nlargest(top_k, filtered_scores, key=lambda x: x[0])\n",
    "\n",
    "    # Get document objects from top indices\n",
    "    reranked_docs = [docs[idx] for _, idx in top_scores]\n",
    "\n",
    "    return top_scores, reranked_docs\n",
    "\n",
    "\n",
    "def formatting_docs(docs:list):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c359c0c-c372-43bc-9c34-42ed73e563a7",
   "metadata": {},
   "source": [
    "# Generate Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da5d5e-bf2f-4238-9352-356b14b32a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# def generate_report_plan(state: ReportState, config: RunnableConfig):\n",
    "#     # Config\n",
    "#     configurable = Configuration.from_runnable_config(config)\n",
    "#     number_of_queries = configurable.number_of_queries\n",
    "\n",
    "#     # inputs\n",
    "#     topic = state[\"topic\"]\n",
    "#     feedback = state.get(\"feedback_on_report_plan\", None)\n",
    "\n",
    "#     # Process\n",
    "#     structured_llm = llm.with_structured_output(Queries)\n",
    "#     system_instructions_query = report_planner_query_writer_instructions.format(topic=topic, report_organization=DEFAULT_REPORT_STRUCTURE, number_of_queries=number_of_queries)\n",
    "#     results = structured_llm.invoke([SystemMessage(content=system_instructions_query), HumanMessage(content=\"보고서의 섹션을 계획하는 데 도움이 되는 검색 쿼리를 생성합니다.\")])\n",
    "#     query_list = [query.search_query for query in results.queries]\n",
    "#     docs = retrieve(queries=query_list)\n",
    "#     source_str = formatting_docs(docs=docs)\n",
    "#     system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=DEFAULT_REPORT_STRUCTURE, context=source_str, feedback=feedback)\n",
    "#     structured_llm = llm.with_structured_output(Sections)\n",
    "#     report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections), HumanMessage(content=planner_message)])\n",
    "#     sections = report_sections.sections\n",
    "#     return {\"sections\": sections}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb828a2-fa06-47c9-bd75-e7ba4f5bb8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "async def generate_report_plan(state: ReportState, config: RunnableConfig):\n",
    "    \"\"\"Generate the initial report plan with sections.\n",
    "    \n",
    "    This node:\n",
    "    1. Gets configuration for the report structure and search parameters\n",
    "    2. Generates search queries to gather context for planning\n",
    "    3. Performs web searches using those queries\n",
    "    4. Uses an LLM to generate a structured plan with sections\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the report topic\n",
    "        config: Configuration for models, search APIs, etc.\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the generated sections\n",
    "    \"\"\"\n",
    "\n",
    "    # Inputs\n",
    "    topic = state[\"topic\"]\n",
    "    feedback = state.get(\"feedback_on_report_plan\", None)\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    report_structure = configurable.report_structure\n",
    "    number_of_queries = configurable.number_of_queries\n",
    "\n",
    "    # Convert JSON object to string if necessary    \n",
    "    if isinstance(report_structure, dict):\n",
    "        report_structure = str(report_structure)\n",
    "\n",
    "    structured_llm = llm.with_structured_output(Queries)\n",
    "    system_instructions_query = report_planner_query_writer_instructions.format(topic=topic, report_organization=report_structure, number_of_queries=number_of_queries)\n",
    "    results = structured_llm.invoke([SystemMessage(content=system_instructions_query), HumanMessage(content=\"보고서의 섹션을 계획하는 데 도움이 되는 검색 쿼리를 생성합니다.\")])\n",
    "    query_list = [query.search_query for query in results.queries]\n",
    "    docs = retrieve(queries=query_list)\n",
    "\n",
    "    # Reranking\n",
    "    top_scores = []\n",
    "    reranked_docs = []\n",
    "    for query in query_list:\n",
    "        top_score, documents = reranking(query=query, docs=docs, min_score = 0.05, top_k= 3)\n",
    "        reranked_docs.extend(documents)\n",
    "        top_scores.extend(top_score)\n",
    "    docs = reranked_docs\n",
    "    \n",
    "    source_str = formatting_docs(docs=docs)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=report_structure, context=source_str, feedback=feedback)\n",
    "\n",
    "    # Report planner instructions\n",
    "    planner_message = \"\"\"보고서의 섹션을 생성합니다. 응답에는 섹션 목록이 포함된 '섹션' 필드가 포함되어야 합니다.\n",
    "    각 섹션에는 이름, 설명, 계획, 연구 및 콘텐츠 필드가 있어야 합니다.\"\"\"\n",
    "    \n",
    "    # Generate the report sections\n",
    "    structured_llm = llm.with_structured_output(Sections)\n",
    "    report_sections = await structured_llm.ainvoke([SystemMessage(content=system_instructions_sections),\n",
    "                                             HumanMessage(content=planner_message)])\n",
    "\n",
    "    # Get sections\n",
    "    sections = report_sections.sections\n",
    "\n",
    "    return {\"sections\": sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3328b37-3743-4ff9-9095-56db21501d70",
   "metadata": {},
   "source": [
    "# Human Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e2586-9b43-438b-81b7-1b9960c03bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "def human_feedback(state: ReportState) -> Command[Literal[\"generate_report_plan\", \"build_section_with_doc_research\"]]:\n",
    "    \"\"\"Get human feedback on the report plan and route to next steps.\n",
    "    \n",
    "    This node:\n",
    "    1. Formats the current report plan for human review\n",
    "    2. Gets feedback via an interrupt\n",
    "    3. Routes to either:\n",
    "       - Section writing if plan is approved\n",
    "       - Plan regeneration if feedback is provided\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state with sections to review\n",
    "        config: Configuration for the workflow\n",
    "        \n",
    "    Returns:\n",
    "        Command to either regenerate plan or start section writing\n",
    "    \"\"\"\n",
    "\n",
    "    # Get sections\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state['sections']\n",
    "    sections_str = \"\\n\\n\".join(\n",
    "        f\"Section: {section.name}\\n\"\n",
    "        f\"Description: {section.description}\\n\"\n",
    "        f\"Research needed: {'Yes' if section.research else 'No'}\\n\"\n",
    "        for section in sections\n",
    "    )\n",
    "\n",
    "    # Get feedback on the report plan from interrupt\n",
    "    interrupt_message = f\"\"\"Please provide feedback on the following report plan. \n",
    "                        \\n\\n{sections_str}\\n\n",
    "                        \\nDoes the report plan meet your needs?\\nPass 'true' to approve the report plan.\\nOr, provide feedback to regenerate the report plan:\"\"\"\n",
    "    print(\">>>> interrupt_message\")\n",
    "    print(interrupt_message)\n",
    "    \n",
    "    feedback = interrupt(interrupt_message)\n",
    "    print(\">>>> feedback\")\n",
    "    print(feedback)\n",
    "\n",
    "    # If the user approves the report plan, kick off section writing\n",
    "    if isinstance(feedback, bool) and feedback is True:\n",
    "        # Treat this as approve and kick off section writing\n",
    "        return Command(goto=[\n",
    "            Send(\"build_section_with_doc_research\", {\"topic\": topic, \"section\": s, \"search_iterations\": 0}) \n",
    "            for s in sections \n",
    "            if s.research\n",
    "        ])\n",
    "    \n",
    "    # If the user provides feedback, regenerate the report plan \n",
    "    elif isinstance(feedback, str):\n",
    "        # Treat this as feedback\n",
    "        return Command(goto=\"generate_report_plan\", \n",
    "                       update={\"feedback_on_report_plan\": feedback})\n",
    "    else:\n",
    "        raise TypeError(f\"Interrupt value of type {type(feedback)} is not supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda0af6-9f57-47d4-9132-47d1e2727654",
   "metadata": {},
   "source": [
    "# Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0087c-e29a-42bb-8ed3-3bfc865963d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_queries(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"Generate search queries for researching a specific section.\n",
    "    \n",
    "    This node uses an LLM to generate targeted search queries based on the \n",
    "    section topic and description.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state containing section details\n",
    "        config: Configuration including number of queries to generate\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the generated search queries\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    number_of_queries = configurable.number_of_queries\n",
    "\n",
    "    # Generate queries \n",
    "    structured_llm = llm.with_structured_output(Queries)\n",
    "\n",
    "    # Format system instructions\n",
    "    system_instructions = query_writer_instructions.format(topic=topic, \n",
    "                                                           section_topic=section.description, \n",
    "                                                           number_of_queries=number_of_queries)\n",
    "\n",
    "    # Generate queries  \n",
    "    queries = await structured_llm.ainvoke([SystemMessage(content=system_instructions),\n",
    "                                     HumanMessage(content=\"제공된 주제에 대한 검색 쿼리를 생성합니다\")])\n",
    "\n",
    "    # print(f\">>> 생성 쿼리 : {queries.queries}\")\n",
    "\n",
    "    return {\"search_queries\": queries.queries}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84501fb-571c-422c-92bd-a951b3f6421c",
   "metadata": {},
   "source": [
    "# Document Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043ed5b-e8e0-4da6-a128-2b9296a40b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def document_search(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"Execute rag document searches for the section queries.\n",
    "    \n",
    "    This node:\n",
    "    1. Takes the generated queries\n",
    "    2. Retrieve Elasticsearch\n",
    "    3. Formats results into usable context\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with search queries        \n",
    "    Returns:\n",
    "        Dict with search results and updated iteration count\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get state\n",
    "    search_queries = state[\"search_queries\"]\n",
    "\n",
    "    # set queries\n",
    "    query_list = [query.search_query for query in search_queries]\n",
    "\n",
    "    # MMR search\n",
    "    docs = retrieve(queries=query_list)\n",
    "\n",
    "    # reranking\n",
    "    top_scores = []\n",
    "    reranked_docs = []\n",
    "    for query in query_list:\n",
    "        top_score, documents = reranking(query=query, docs=docs, min_score = 0.1, top_k= 3)\n",
    "        reranked_docs.extend(documents)\n",
    "        top_scores.extend(top_score)\n",
    "    docs = reranked_docs\n",
    "\n",
    "    print(f\">>> 검색 문서 개수: {len(docs)}\")\n",
    "    \n",
    "    source_str = formatting_docs(docs=docs)\n",
    "\n",
    "    return {\"source_str\": source_str, \"search_iterations\": state[\"search_iterations\"] + 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af267d02-1f89-4436-8dd7-0cb033208fea",
   "metadata": {},
   "source": [
    "# Write Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371f9b4-d893-423c-a90c-38a675e822fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "async def write_section(state: SectionState, config: RunnableConfig) -> Command[Literal[END, \"document_search\"]]:\n",
    "    \"\"\"Write a section of the report and evaluate if more research is needed.\n",
    "    \n",
    "    This node:\n",
    "    1. Writes section content using search results\n",
    "    2. Evaluates the quality of the section\n",
    "    3. Either:\n",
    "       - Completes the section if quality passes\n",
    "       - Triggers more research if quality fails\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with search results and section info\n",
    "        config: Configuration for writing and evaluation\n",
    "        \n",
    "    Returns:\n",
    "        Command to either complete section or do more research\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "    source_str = state[\"source_str\"]\n",
    "\n",
    "    # Get configuration\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Format system instructions\n",
    "    section_writer_inputs_formatted = section_writer_inputs.format(topic=topic, \n",
    "                                                             section_name=section.name, \n",
    "                                                             section_topic=section.description, \n",
    "                                                             context=source_str, \n",
    "                                                             section_content=section.content)\n",
    "\n",
    "    # Generate section  \n",
    "    # writer_provider = get_config_value(configurable.writer_provider)\n",
    "    # writer_model_name = get_config_value(configurable.writer_model)\n",
    "    # writer_model_kwargs = get_config_value(configurable.writer_model_kwargs or {})\n",
    "    # writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, model_kwargs=writer_model_kwargs) \n",
    "\n",
    "    section_content = await llm.ainvoke([SystemMessage(content=section_writer_instructions),\n",
    "                                           HumanMessage(content=section_writer_inputs_formatted)])\n",
    "    \n",
    "    # Write content to the section object  \n",
    "    section.content = section_content.content\n",
    "\n",
    "    # Grade prompt \n",
    "    section_grader_message = (\"보고서를 평가하고 누락된 정보에 대한 후속 질문을 고려합니다.\"\n",
    "                          \"보고서 평가결과가 'pass'인 경우 모든 후속 쿼리에 빈 문자열을 반환합니다.\"\n",
    "                          \"보고서 평가결과가 'fail'인 경우 누락된 정보를 수집하기 위해 특정 검색 쿼리를 제공합니다.\"\n",
    "                         )\n",
    "    section_grader_instructions_formatted = section_grader_instructions.format(topic=topic, \n",
    "                                                                               section_topic=section.description,\n",
    "                                                                               section=section.content, \n",
    "                                                                               number_of_follow_up_queries=configurable.number_of_queries)\n",
    "\n",
    "    # Use planner model for reflection\n",
    "    # planner_provider = get_config_value(configurable.planner_provider)\n",
    "    # planner_model = get_config_value(configurable.planner_model)\n",
    "    # planner_model_kwargs = get_config_value(configurable.planner_model_kwargs or {})\n",
    "\n",
    "    \n",
    "    reflection_model = llm.with_structured_output(Feedback)\n",
    "    \n",
    "    feedback = await reflection_model.ainvoke([SystemMessage(content=section_grader_instructions_formatted),\n",
    "                                        HumanMessage(content=section_grader_message)])\n",
    "\n",
    "    # print(f\">>> 피드백 : {feedback}\")\n",
    "\n",
    "    # If the section is passing or the max search depth is reached, publish the section to completed sections \n",
    "    if feedback.grade == \"pass\" or state[\"search_iterations\"] >= configurable.max_search_depth:\n",
    "        # Publish the section to completed sections \n",
    "        return  Command(\n",
    "        update={\"completed_sections\": [section]},\n",
    "        goto=END\n",
    "    )\n",
    "\n",
    "    # Update the existing section with new content and update search queries\n",
    "    else:\n",
    "        return  Command(\n",
    "        update={\"search_queries\": feedback.follow_up_queries, \"section\": section},\n",
    "        goto=\"document_search\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213278aa-d88f-47d7-9317-1ef77b31f5a0",
   "metadata": {},
   "source": [
    "# Gather Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a38a1c-bbfe-4002-8646-9eac90d80f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_completed_sections(state: ReportState):\n",
    "    \"\"\"Format completed sections as context for writing final sections.\n",
    "    \n",
    "    This node takes all completed research sections and formats them into\n",
    "    a single context string for writing summary sections.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with completed sections\n",
    "        \n",
    "    Returns:\n",
    "        Dict with formatted sections as context\n",
    "    \"\"\"\n",
    "    \n",
    "    # List of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # print(f\">>> completed_sections : {completed_sections}\")\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_sections = format_sections(completed_sections)\n",
    "\n",
    "    return {\"report_sections_from_research\": completed_report_sections}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee793f8-0dbf-42ae-babd-ec839f088143",
   "metadata": {},
   "source": [
    "# Write Final Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a415ba-62dd-4773-959e-ad0e14bfa14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def write_final_sections(state: SectionState, config: RunnableConfig):\n",
    "    \"\"\"Write sections that don't require research using completed sections as context.\n",
    "    \n",
    "    This node handles sections like conclusions or summaries that build on\n",
    "    the researched sections rather than requiring direct research.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with completed sections as context\n",
    "        config: Configuration for the writing model\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the newly written section\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get configuration\n",
    "    # configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Get state \n",
    "    topic = state[\"topic\"]\n",
    "    section = state[\"section\"]\n",
    "    completed_report_sections = state[\"report_sections_from_research\"]\n",
    "    \n",
    "    # Format system instructions\n",
    "    system_instructions = final_section_writer_instructions.format(topic=topic, section_name=section.name, section_topic=section.description, context=completed_report_sections)\n",
    "\n",
    "    # Generate section  \n",
    "    # writer_provider = get_config_value(configurable.writer_provider)\n",
    "    # writer_model_name = get_config_value(configurable.writer_model)\n",
    "    # writer_model_kwargs = get_config_value(configurable.writer_model_kwargs or {})\n",
    "    # writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, model_kwargs=writer_model_kwargs) \n",
    "    \n",
    "    section_content = await llm.ainvoke([SystemMessage(content=system_instructions),\n",
    "                                           HumanMessage(content=\"제공된 소스를 기반으로 보고서 섹션을 생성합니다.\")])\n",
    "    \n",
    "    # Write content to section \n",
    "    section.content = section_content.content\n",
    "\n",
    "    # print(f\">>> section.content : {section.content}\")\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb723a86-a18f-4e37-80c7-685755c0f63b",
   "metadata": {},
   "source": [
    "# Compile Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f50d8-2549-4131-a213-3162f0bed0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_final_report(state: ReportState):\n",
    "    \"\"\"Compile all sections into the final report.\n",
    "    \n",
    "    This node:\n",
    "    1. Gets all completed sections\n",
    "    2. Orders them according to original plan\n",
    "    3. Combines them into the final report\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with all completed sections\n",
    "        \n",
    "    Returns:\n",
    "        Dict containing the complete report\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get sections\n",
    "    sections = state[\"sections\"]\n",
    "    completed_sections = {s.name: s.content for s in state[\"completed_sections\"]}\n",
    "\n",
    "    # Update sections with completed content while maintaining original order\n",
    "    for section in sections:\n",
    "        section.content = completed_sections[section.name]\n",
    "\n",
    "    # Compile final report\n",
    "    all_sections = \"\\n\\n\".join([s.content for s in sections])\n",
    "\n",
    "    # print(f\">>> all_sections : {all_sections}\")\n",
    "\n",
    "    return {\"final_report\": all_sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba203133-9880-4d1c-8cfa-7cf9cd551834",
   "metadata": {},
   "source": [
    "# Init Final Section Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858da275-4aa4-47de-aded-dfa89980901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_final_section_writing(state: ReportState):\n",
    "    \"\"\"Create parallel tasks for writing non-research sections.\n",
    "    \n",
    "    This edge function identifies sections that don't need research and\n",
    "    creates parallel writing tasks for each one.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with all sections and research context\n",
    "        \n",
    "    Returns:\n",
    "        List of Send commands for parallel section writing\n",
    "    \"\"\"\n",
    "    \n",
    "    # Kick off section writing in parallel via Send() API for any sections that do not require research\n",
    "    return [\n",
    "        Send(\"write_final_sections\", {\"topic\": state[\"topic\"], \"section\": s, \"report_sections_from_research\": state[\"report_sections_from_research\"]}) \n",
    "        for s in state[\"sections\"] \n",
    "        if not s.research\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d48b9-6782-44b7-b36c-0c8cfb49d87e",
   "metadata": {},
   "source": [
    "# Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144c71a-dbb4-4e60-880b-0e14e0a1d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display, Markdown\n",
    "\n",
    "section_builder = StateGraph(SectionState, output=SectionOutputState)\n",
    "section_builder.add_node(\"generate_queries\", generate_queries)\n",
    "section_builder.add_node(\"document_search\", document_search)\n",
    "section_builder.add_node(\"write_section\", write_section)\n",
    "\n",
    "# Add edges\n",
    "section_builder.add_edge(START, \"generate_queries\")\n",
    "section_builder.add_edge(\"generate_queries\", \"document_search\")\n",
    "section_builder.add_edge(\"document_search\", \"write_section\")\n",
    "\n",
    "\n",
    "builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)\n",
    "builder.add_node(\"generate_report_plan\", generate_report_plan)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "builder.add_node(\"build_section_with_doc_research\", section_builder.compile())\n",
    "builder.add_node(\"gather_completed_sections\", gather_completed_sections)\n",
    "builder.add_node(\"write_final_sections\", write_final_sections)\n",
    "builder.add_node(\"compile_final_report\", compile_final_report)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"generate_report_plan\")\n",
    "builder.add_edge(\"generate_report_plan\", \"human_feedback\")\n",
    "builder.add_edge(\"build_section_with_doc_research\", \"gather_completed_sections\")\n",
    "builder.add_conditional_edges(\"gather_completed_sections\", initiate_final_section_writing, [\"write_final_sections\"])\n",
    "builder.add_edge(\"write_final_sections\", \"compile_final_report\")\n",
    "builder.add_edge(\"compile_final_report\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014afeb-7fc7-4338-ad25-e05ee3c7738a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cc492-cf3e-4116-a845-42b8052f7971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import uuid \n",
    "from IPython.display import Markdown\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"max_search_depth\": 1,\n",
    "                           \"report_structure\": report_structure,}\n",
    "                           }\n",
    "\n",
    "topic = \"당신은 조선소의 안전 관리자 입니다. 산업안전보건법상 건설공사 도급과 관련한 안전·보건조치의무 및 그 위반에 따른 형사처벌 규정을 해석할 때 고려하여야 할 사항에 대해 단계적으로 검토후 보고서를 작성해주세요.\"\n",
    "async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca26bf-6536-41a4-97c5-26196c9c05c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feedback_msg = \"\"\"\n",
    "도급공사 안전사고에 관한 판례의 내용도 하나의 섹션으로 추가해주세요.\n",
    "\"\"\"\n",
    "\n",
    "async for event in graph.astream(Command(resume=feedback_msg), thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcdf5f9-eab1-4232-934c-60d093a76d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feedback_msg = True\n",
    "\n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c655c3-52b2-43c5-b55a-6a24979909cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e43e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
