{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97e66be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16128bb",
   "metadata": {},
   "source": [
    "# State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40930e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from dataclasses import dataclass, field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryState:\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "    search_query: str = field(default=None) # Search query\n",
    "    web_research_results: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    sources_gathered: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    research_loop_count: int = field(default=0) # Research loop count\n",
    "    running_summary: str = field(default=None) # Final report\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateInput:\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateOutput:\n",
    "    running_summary: str = field(default=None) # Final report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf50772",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e26adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Optional, Literal\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "class SearchAPI(Enum):\n",
    "    PERPLEXITY = \"perplexity\"\n",
    "    TAVILY = \"tavily\"\n",
    "    DUCKDUCKGO = \"duckduckgo\"\n",
    "    SEARXNG = \"searxng\"\n",
    "\n",
    "class Configuration(BaseModel):\n",
    "    \"\"\"The configurable fields for the research assistant.\"\"\"\n",
    "\n",
    "    max_web_research_loops: int = Field(\n",
    "        default=3,\n",
    "        title=\"Research Depth\",\n",
    "        description=\"Number of research iterations to perform\"\n",
    "    )\n",
    "    local_llm: str = Field(\n",
    "        default=\"qwen3:4b\",\n",
    "        title=\"LLM Model Name\",\n",
    "        description=\"Name of the LLM model to use\"\n",
    "    )\n",
    "    llm_provider: Literal[\"ollama\", \"lmstudio\"] = Field(\n",
    "        default=\"ollama\",\n",
    "        title=\"LLM Provider\",\n",
    "        description=\"Provider for the LLM (Ollama or LMStudio)\"\n",
    "    )\n",
    "    search_api: Literal[\"perplexity\", \"tavily\", \"duckduckgo\", \"searxng\"] = Field(\n",
    "        default=\"tavily\",\n",
    "        title=\"Search API\",\n",
    "        description=\"Web search API to use\"\n",
    "    )\n",
    "    fetch_full_page: bool = Field(\n",
    "        default=True,\n",
    "        title=\"Fetch Full Page\",\n",
    "        description=\"Include the full page content in the search results\"\n",
    "    )\n",
    "    ollama_base_url: str = Field(\n",
    "        default=\"http://localhost:11434/\",\n",
    "        title=\"Ollama Base URL\",\n",
    "        description=\"Base URL for Ollama API\"\n",
    "    )\n",
    "    lmstudio_base_url: str = Field(\n",
    "        default=\"http://localhost:1234/v1\",\n",
    "        title=\"LMStudio Base URL\",\n",
    "        description=\"Base URL for LMStudio OpenAI-compatible API\"\n",
    "    )\n",
    "    strip_thinking_tokens: bool = Field(\n",
    "        default=True,\n",
    "        title=\"Strip Thinking Tokens\",\n",
    "        description=\"Whether to strip <think> tokens from model responses\"\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "        \n",
    "        # Get raw values from environment or config\n",
    "        raw_values: dict[str, Any] = {\n",
    "            name: os.environ.get(name.upper(), configurable.get(name))\n",
    "            for name in cls.model_fields.keys()\n",
    "        }\n",
    "        \n",
    "        # Filter out None values\n",
    "        values = {k: v for k, v in raw_values.items() if v is not None}\n",
    "        \n",
    "        return cls(**values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc59361",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb1a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import requests\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "\n",
    "from markdownify import markdownify\n",
    "from langsmith import traceable\n",
    "from tavily import TavilyClient\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "from langchain_community.utilities import SearxSearchWrapper\n",
    "\n",
    "def get_config_value(value: Any) -> str:\n",
    "    \"\"\"\n",
    "    Convert configuration values to string format, handling both string and enum types.\n",
    "    \n",
    "    Args:\n",
    "        value (Any): The configuration value to process. Can be a string or an Enum.\n",
    "    \n",
    "    Returns:\n",
    "        str: The string representation of the value.\n",
    "        \n",
    "    Examples:\n",
    "        >>> get_config_value(\"tavily\")\n",
    "        'tavily'\n",
    "        >>> get_config_value(SearchAPI.TAVILY)\n",
    "        'tavily'\n",
    "    \"\"\"\n",
    "    return value if isinstance(value, str) else value.value\n",
    "\n",
    "def strip_thinking_tokens(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove <think> and </think> tags and their content from the text.\n",
    "    \n",
    "    Iteratively removes all occurrences of content enclosed in thinking tokens.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to process\n",
    "        \n",
    "    Returns:\n",
    "        str: The text with thinking tokens and their content removed\n",
    "    \"\"\"\n",
    "    while \"<think>\" in text and \"</think>\" in text:\n",
    "        start = text.find(\"<think>\")\n",
    "        end = text.find(\"</think>\") + len(\"</think>\")\n",
    "        text = text[:start] + text[end:]\n",
    "    return text\n",
    "\n",
    "def deduplicate_and_format_sources(\n",
    "    search_response: Union[Dict[str, Any], List[Dict[str, Any]]], \n",
    "    max_tokens_per_source: int, \n",
    "    fetch_full_page: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Format and deduplicate search responses from various search APIs.\n",
    "    \n",
    "    Takes either a single search response or list of responses from search APIs,\n",
    "    deduplicates them by URL, and formats them into a structured string.\n",
    "    \n",
    "    Args:\n",
    "        search_response (Union[Dict[str, Any], List[Dict[str, Any]]]): Either:\n",
    "            - A dict with a 'results' key containing a list of search results\n",
    "            - A list of dicts, each containing search results\n",
    "        max_tokens_per_source (int): Maximum number of tokens to include for each source's content\n",
    "        fetch_full_page (bool, optional): Whether to include the full page content. Defaults to False.\n",
    "            \n",
    "    Returns:\n",
    "        str: Formatted string with deduplicated sources\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If input is neither a dict with 'results' key nor a list of search results\n",
    "    \"\"\"\n",
    "    # Convert input to list of results\n",
    "    if isinstance(search_response, dict):\n",
    "        sources_list = search_response['results']\n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                sources_list.extend(response['results'])\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "    \n",
    "    # Deduplicate by URL\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        if source['url'] not in unique_sources:\n",
    "            unique_sources[source['url']] = source\n",
    "    \n",
    "    # Format output\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"Source: {source['title']}\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if fetch_full_page:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "                \n",
    "    return formatted_text.strip()\n",
    "\n",
    "def format_sources(search_results: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Format search results into a bullet-point list of sources with URLs.\n",
    "    \n",
    "    Creates a simple bulleted list of search results with title and URL for each source.\n",
    "    \n",
    "    Args:\n",
    "        search_results (Dict[str, Any]): Search response containing a 'results' key with\n",
    "                                        a list of search result objects\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string with sources as bullet points in the format \"* title : url\"\n",
    "    \"\"\"\n",
    "    return '\\n'.join(\n",
    "        f\"* {source['title']} : {source['url']}\"\n",
    "        for source in search_results['results']\n",
    "    )\n",
    "\n",
    "def fetch_raw_content(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch HTML content from a URL and convert it to markdown format.\n",
    "    \n",
    "    Uses a 10-second timeout to avoid hanging on slow sites or large pages.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to fetch content from\n",
    "        \n",
    "    Returns:\n",
    "        Optional[str]: The fetched content converted to markdown if successful,\n",
    "                      None if any error occurs during fetching or conversion\n",
    "    \"\"\"\n",
    "    try:                \n",
    "        # Create a client with reasonable timeout\n",
    "        with httpx.Client(timeout=10.0) as client:\n",
    "            response = client.get(url)\n",
    "            response.raise_for_status()\n",
    "            return markdownify(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to fetch full page content for {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "@traceable\n",
    "def duckduckgo_search(query: str, max_results: int = 3, fetch_full_page: bool = False) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Search the web using DuckDuckGo and return formatted results.\n",
    "    \n",
    "    Uses the DDGS library to perform web searches through DuckDuckGo.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        max_results (int, optional): Maximum number of results to return. Defaults to 3.\n",
    "        fetch_full_page (bool, optional): Whether to fetch full page content from result URLs. \n",
    "                                         Defaults to False.\n",
    "    Returns:\n",
    "        Dict[str, List[Dict[str, Any]]]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str or None): Full page content if fetch_full_page is True,\n",
    "                                            otherwise same as content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = []\n",
    "            search_results = list(ddgs.text(query, max_results=max_results))\n",
    "            \n",
    "            for r in search_results:\n",
    "                url = r.get('href')\n",
    "                title = r.get('title')\n",
    "                content = r.get('body')\n",
    "                \n",
    "                if not all([url, title, content]):\n",
    "                    print(f\"Warning: Incomplete result from DuckDuckGo: {r}\")\n",
    "                    continue\n",
    "\n",
    "                raw_content = content\n",
    "                if fetch_full_page:\n",
    "                    raw_content = fetch_raw_content(url)\n",
    "                \n",
    "                # Add result to list\n",
    "                result = {\n",
    "                    \"title\": title,\n",
    "                    \"url\": url,\n",
    "                    \"content\": content,\n",
    "                    \"raw_content\": raw_content\n",
    "                }\n",
    "                results.append(result)\n",
    "            \n",
    "            return {\"results\": results}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DuckDuckGo search: {str(e)}\")\n",
    "        print(f\"Full error details: {type(e).__name__}\")\n",
    "        return {\"results\": []}\n",
    "\n",
    "@traceable\n",
    "def searxng_search(query: str, max_results: int = 3, fetch_full_page: bool = False) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Search the web using SearXNG and return formatted results.\n",
    "    \n",
    "    Uses the SearxSearchWrapper to perform searches through a SearXNG instance.\n",
    "    The SearXNG host URL is read from the SEARXNG_URL environment variable\n",
    "    or defaults to http://localhost:8888.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        max_results (int, optional): Maximum number of results to return. Defaults to 3.\n",
    "        fetch_full_page (bool, optional): Whether to fetch full page content from result URLs.\n",
    "                                         Defaults to False.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List[Dict[str, Any]]]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str or None): Full page content if fetch_full_page is True,\n",
    "                                           otherwise same as content\n",
    "    \"\"\"\n",
    "    host=os.environ.get(\"SEARXNG_URL\", \"http://localhost:8888\")\n",
    "    s = SearxSearchWrapper(searx_host=host)\n",
    "\n",
    "    results = []\n",
    "    search_results = s.results(query, num_results=max_results)\n",
    "    for r in search_results:\n",
    "        url = r.get('link')\n",
    "        title = r.get('title')\n",
    "        content = r.get('snippet')\n",
    "        \n",
    "        if not all([url, title, content]):\n",
    "            print(f\"Warning: Incomplete result from SearXNG: {r}\")\n",
    "            continue\n",
    "\n",
    "        raw_content = content\n",
    "        if fetch_full_page:\n",
    "            raw_content = fetch_raw_content(url)\n",
    "        \n",
    "        # Add result to list\n",
    "        result = {\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"content\": content,\n",
    "            \"raw_content\": raw_content\n",
    "        }\n",
    "        results.append(result)\n",
    "    return {\"results\": results}\n",
    "    \n",
    "@traceable\n",
    "def tavily_search(query: str, fetch_full_page: bool = True, max_results: int = 3) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Search the web using the Tavily API and return formatted results.\n",
    "    \n",
    "    Uses the TavilyClient to perform searches. Tavily API key must be configured\n",
    "    in the environment.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        fetch_full_page (bool, optional): Whether to include raw content from sources.\n",
    "                                         Defaults to True.\n",
    "        max_results (int, optional): Maximum number of results to return. Defaults to 3.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List[Dict[str, Any]]]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str or None): Full content of the page if available and \n",
    "                                            fetch_full_page is True\n",
    "    \"\"\"\n",
    "     \n",
    "    tavily_client = TavilyClient()\n",
    "    return tavily_client.search(query, \n",
    "                         max_results=max_results, \n",
    "                         include_raw_content=fetch_full_page)\n",
    "\n",
    "@traceable\n",
    "def perplexity_search(query: str, perplexity_search_loop_count: int = 0) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search the web using the Perplexity API and return formatted results.\n",
    "    \n",
    "    Uses the Perplexity API to perform searches with the 'sonar-pro' model.\n",
    "    Requires a PERPLEXITY_API_KEY environment variable to be set.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        perplexity_search_loop_count (int, optional): The loop step for perplexity search\n",
    "                                                     (used for source labeling). Defaults to 0.\n",
    "  \n",
    "    Returns:\n",
    "        Dict[str, Any]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result (includes search counter)\n",
    "                - url (str): URL of the citation source\n",
    "                - content (str): Content of the response or reference to main content\n",
    "                - raw_content (str or None): Full content for the first source, None for additional\n",
    "                                            citation sources\n",
    "                                            \n",
    "    Raises:\n",
    "        requests.exceptions.HTTPError: If the API request fails\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.getenv('PERPLEXITY_API_KEY')}\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"sonar-pro\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Search the web and provide factual information with sources.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        \"https://api.perplexity.ai/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    response.raise_for_status()  # Raise exception for bad status codes\n",
    "    \n",
    "    # Parse the response\n",
    "    data = response.json()\n",
    "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # Perplexity returns a list of citations for a single search result\n",
    "    citations = data.get(\"citations\", [\"https://perplexity.ai\"])\n",
    "    \n",
    "    # Return first citation with full content, others just as references\n",
    "    results = [{\n",
    "        \"title\": f\"Perplexity Search {perplexity_search_loop_count + 1}, Source 1\",\n",
    "        \"url\": citations[0],\n",
    "        \"content\": content,\n",
    "        \"raw_content\": content\n",
    "    }]\n",
    "    \n",
    "    # Add additional citations without duplicating content\n",
    "    for i, citation in enumerate(citations[1:], start=2):\n",
    "        results.append({\n",
    "            \"title\": f\"Perplexity Search {perplexity_search_loop_count + 1}, Source {i}\",\n",
    "            \"url\": citation,\n",
    "            \"content\": \"See above for full content\",\n",
    "            \"raw_content\": None\n",
    "        })\n",
    "    \n",
    "    return {\"results\": results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456cb91",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9b3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get current date in a readable format\n",
    "def get_current_date():\n",
    "    return datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "query_writer_instructions=\"\"\"Your goal is to generate a targeted web search query.\n",
    "\n",
    "<CONTEXT>\n",
    "Current date: {current_date}\n",
    "Please ensure your queries account for the most current information available as of this date.\n",
    "</CONTEXT>\n",
    "\n",
    "<TOPIC>\n",
    "{research_topic}\n",
    "</TOPIC>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with ALL three of these exact keys:\n",
    "   - \"query\": The actual search query string\n",
    "   - \"rationale\": Brief explanation of why this query is relevant\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"query\": \"machine learning transformer architecture explained\",\n",
    "    \"rationale\": \"Understanding the fundamental structure of transformer models\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your response in JSON format:\"\"\"\n",
    "\n",
    "summarizer_instructions=\"\"\"\n",
    "<GOAL>\n",
    "Generate a high-quality summary of the provided context.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant information related to the user topic from the search results\n",
    "2. Ensure a coherent flow of information\n",
    "\n",
    "When EXTENDING an existing summary:                                                                                                                 \n",
    "1. Read the existing summary and new search results carefully.                                                    \n",
    "2. Compare the new information with the existing summary.                                                         \n",
    "3. For each piece of new information:                                                                             \n",
    "    a. If it's related to existing points, integrate it into the relevant paragraph.                               \n",
    "    b. If it's entirely new but relevant, add a new paragraph with a smooth transition.                            \n",
    "    c. If it's not relevant to the user topic, skip it.                                                            \n",
    "4. Ensure all additions are relevant to the user's topic.                                                         \n",
    "5. Verify that your final output differs from the input summary.                                                                                                                                                            \n",
    "< /REQUIREMENTS >\n",
    "\n",
    "< FORMATTING >\n",
    "- Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.  \n",
    "< /FORMATTING >\n",
    "\n",
    "<Task>\n",
    "Think carefully about the provided Context first. Then generate a summary of the context to address the User Input.\n",
    "</Task>\n",
    "\"\"\"\n",
    "\n",
    "reflection_instructions = \"\"\"You are an expert research assistant analyzing a summary about {research_topic}.\n",
    "\n",
    "<GOAL>\n",
    "1. Identify knowledge gaps or areas that need deeper exploration\n",
    "2. Generate a follow-up question that would help expand your understanding\n",
    "3. Focus on technical details, implementation specifics, or emerging trends that weren't fully covered\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "Ensure the follow-up question is self-contained and includes necessary context for web search.\n",
    "</REQUIREMENTS>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with these exact keys:\n",
    "- knowledge_gap: Describe what information is missing or needs clarification\n",
    "- follow_up_query: Write a specific question to address this gap\n",
    "</FORMAT>\n",
    "\n",
    "<Task>\n",
    "Reflect carefully on the Summary to identify knowledge gaps and produce a follow-up query. Then, produce your output following this JSON format:\n",
    "{{\n",
    "    \"knowledge_gap\": \"The summary lacks information about performance metrics and benchmarks\",\n",
    "    \"follow_up_query\": \"What are typical performance benchmarks and metrics used to evaluate [specific technology]?\"\n",
    "}}\n",
    "</Task>\n",
    "\n",
    "Provide your analysis in JSON format:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432293d",
   "metadata": {},
   "source": [
    "# Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# api_key=os.environ.get(\"openrouter_api_key\")\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model = \"qwen/qwen3-14b:free\", # \"qwen/qwen3-14b:free\", \"qwen/qwen3-30b-a3b:free\",\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=api_key,\n",
    "#     temperature=0,\n",
    "#     )\n",
    "\n",
    "# llm_json_mode = ChatOpenAI(\n",
    "#     model = \"qwen/qwen3-14b:free\", # \"qwen/qwen3-14b:free\", \"qwen/qwen3-30b-a3b:free\",\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=api_key,\n",
    "#     temperature=0,\n",
    "#     response_format=\"json\"  # structured output mode\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a822908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000249A517FD70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "# from ollama_deep_researcher.configuration import Configuration, SearchAPI\n",
    "# from ollama_deep_researcher.utils import deduplicate_and_format_sources, tavily_search, format_sources, perplexity_search, duckduckgo_search, searxng_search, strip_thinking_tokens, get_config_value\n",
    "# from ollama_deep_researcher.state import SummaryState, SummaryStateInput, SummaryStateOutput\n",
    "# from ollama_deep_researcher.prompts import query_writer_instructions, summarizer_instructions, reflection_instructions, get_current_date\n",
    "# from ollama_deep_researcher.lmstudio import ChatLMStudio\n",
    "\n",
    "# Nodes\n",
    "def generate_query(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that generates a search query based on the research topic.\n",
    "    \n",
    "    Uses an LLM to create an optimized search query for web research based on\n",
    "    the user's research topic. Supports both LMStudio and Ollama as LLM providers.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the research topic\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated query\n",
    "    \"\"\"\n",
    "    print(\"---------<Generate Queries>--------------\")\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = query_writer_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=state.research_topic\n",
    "    )\n",
    "\n",
    "    # Generate a query\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    # Choose the appropriate LLM based on the provider\n",
    "    llm_json_mode = ChatOllama(\n",
    "        base_url=configurable.ollama_base_url, \n",
    "        model=configurable.local_llm, \n",
    "        temperature=0, \n",
    "        format=\"json\"\n",
    "        )\n",
    "    \n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=f\"Generate a query for web search:\")]\n",
    "    )\n",
    "    \n",
    "    # Get the content\n",
    "    content = result.content\n",
    "\n",
    "    # Parse the JSON response and get the query\n",
    "    try:\n",
    "        query = json.loads(content)\n",
    "        search_query = query['query']\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        # If parsing fails or the key is not found, use a fallback query\n",
    "        if configurable.strip_thinking_tokens:\n",
    "            content = strip_thinking_tokens(content)\n",
    "        search_query = content\n",
    "    print(f\">>> Search Query: {search_query}\")\n",
    "    return {\"search_query\": search_query}\n",
    "\n",
    "def web_research(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that performs web research using the generated search query.\n",
    "    \n",
    "    Executes a web search using the configured search API (tavily, perplexity, \n",
    "    duckduckgo, or searxng) and formats the results for further processing.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the search query and research loop count\n",
    "        config: Configuration for the runnable, including search API settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "    \"\"\"\n",
    "    print(\"---------<Web Research>--------------\")\n",
    "    # Configure\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Get the search API\n",
    "    search_api = get_config_value(configurable.search_api)\n",
    "\n",
    "    # Search the web\n",
    "    if search_api == \"tavily\":\n",
    "        search_results = tavily_search(state.search_query, fetch_full_page=configurable.fetch_full_page, max_results=1)\n",
    "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, fetch_full_page=configurable.fetch_full_page)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search API: {configurable.search_api}\")\n",
    "    \n",
    "    print(f\">>> web_research_results: {search_str}\")\n",
    "    return {\"sources_gathered\": [format_sources(search_results)], \"research_loop_count\": state.research_loop_count + 1, \"web_research_results\": [search_str]}\n",
    "\n",
    "def summarize_sources(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that summarizes web research results.\n",
    "    \n",
    "    Uses an LLM to create or update a running summary based on the newest web research \n",
    "    results, integrating them with any existing summary.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing research topic, running summary,\n",
    "              and web research results\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including running_summary key containing the updated summary\n",
    "    \"\"\"\n",
    "    print(\"---------<Summarize Sources>--------------\")\n",
    "    # Existing summary\n",
    "    existing_summary = state.running_summary\n",
    "\n",
    "    # Most recent web research\n",
    "    most_recent_web_research = state.web_research_results[-1]\n",
    "\n",
    "    # Build the human message\n",
    "    if existing_summary:\n",
    "        human_message_content = (\n",
    "            f\"<Existing Summary> \\n {existing_summary} \\n <Existing Summary>\\n\\n\"\n",
    "            f\"<New Context> \\n {most_recent_web_research} \\n <New Context>\"\n",
    "            f\"Update the Existing Summary with the New Context on this topic: \\n <User Input> \\n {state.research_topic} \\n <User Input>\\n\\n\"\n",
    "        )\n",
    "    else:\n",
    "        human_message_content = (\n",
    "            f\"<Context> \\n {most_recent_web_research} \\n <Context>\"\n",
    "            f\"Create a Summary using the Context on this topic: \\n <User Input> \\n {state.research_topic} \\n <User Input>\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # Run the LLM\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    # Choose the appropriate LLM based on the provider\n",
    "    llm = ChatOllama(\n",
    "        base_url=configurable.ollama_base_url, \n",
    "        model=configurable.local_llm, \n",
    "        temperature=0\n",
    "        )\n",
    "    \n",
    "    result = llm.invoke(\n",
    "        [SystemMessage(content=summarizer_instructions),\n",
    "        HumanMessage(content=human_message_content)]\n",
    "    )\n",
    "\n",
    "    # Strip thinking tokens if configured\n",
    "    running_summary = result.content\n",
    "    if configurable.strip_thinking_tokens:\n",
    "        running_summary = strip_thinking_tokens(running_summary)\n",
    "\n",
    "    print(f\">>> running_summary: {running_summary}\")\n",
    "    return {\"running_summary\": running_summary}\n",
    "\n",
    "def reflect_on_summary(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that identifies knowledge gaps and generates follow-up queries.\n",
    "    \n",
    "    Analyzes the current summary to identify areas for further research and generates\n",
    "    a new search query to address those gaps. Uses structured output to extract\n",
    "    the follow-up query in JSON format.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and research topic\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated follow-up query\n",
    "    \"\"\"\n",
    "    print(\"---------<Reflect on Summary>--------------\")\n",
    "    # Generate a query\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    # Choose the appropriate LLM based on the provider\n",
    "    llm_json_mode = ChatOllama(\n",
    "        base_url=configurable.ollama_base_url, \n",
    "        model=configurable.local_llm, \n",
    "        temperature=0, \n",
    "        format=\"json\"\n",
    "        )\n",
    "    \n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=reflection_instructions.format(research_topic=state.research_topic)),\n",
    "        HumanMessage(content=f\"Reflect on our existing knowledge: \\n === \\n {state.running_summary}, \\n === \\n And now identify a knowledge gap and generate a follow-up web search query:\")]\n",
    "    )\n",
    "    \n",
    "    # Strip thinking tokens if configured\n",
    "    try:\n",
    "        # Try to parse as JSON first\n",
    "        reflection_content = json.loads(result.content)\n",
    "        # Get the follow-up query\n",
    "        query = reflection_content.get('follow_up_query')\n",
    "        # Check if query is None or empty\n",
    "        if not query:\n",
    "            # Use a fallback query\n",
    "            return {\"search_query\": f\"Tell me more about {state.research_topic}\"}\n",
    "        print(f\">>> Not Query_search_query: {query}\")\n",
    "        return {\"search_query\": query}\n",
    "    except (json.JSONDecodeError, KeyError, AttributeError):\n",
    "        # If parsing fails or the key is not found, use a fallback query\n",
    "        print(f\"Tell me more about {state.research_topic}\")\n",
    "        return {\"search_query\": f\"Tell me more about {state.research_topic}\"}\n",
    "        \n",
    "def finalize_summary(state: SummaryState):\n",
    "    \"\"\"LangGraph node that finalizes the research summary.\n",
    "    \n",
    "    Prepares the final output by deduplicating and formatting sources, then\n",
    "    combining them with the running summary to create a well-structured\n",
    "    research report with proper citations.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and sources gathered\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including running_summary key containing the formatted final summary with sources\n",
    "    \"\"\"\n",
    "    print(\"---------<Finalize Summary>--------------\")\n",
    "    # Deduplicate sources before joining\n",
    "    seen_sources = set()\n",
    "    unique_sources = []\n",
    "    \n",
    "    for source in state.sources_gathered:\n",
    "        # Split the source into lines and process each individually\n",
    "        for line in source.split('\\n'):\n",
    "            # Only process non-empty lines\n",
    "            if line.strip() and line not in seen_sources:\n",
    "                seen_sources.add(line)\n",
    "                unique_sources.append(line)\n",
    "    \n",
    "    # Join the deduplicated sources\n",
    "    all_sources = \"\\n\".join(unique_sources)\n",
    "    state.running_summary = f\"## Summary\\n{state.running_summary}\\n\\n ### Sources:\\n{all_sources}\"\n",
    "    print(f\">>> running_summary: {state.running_summary}\")\n",
    "    return {\"running_summary\": state.running_summary}\n",
    "\n",
    "def route_research(state: SummaryState, config: RunnableConfig) -> Literal[\"finalize_summary\", \"web_research\"]:\n",
    "    \"\"\"LangGraph routing function that determines the next step in the research flow.\n",
    "    \n",
    "    Controls the research loop by deciding whether to continue gathering information\n",
    "    or to finalize the summary based on the configured maximum number of research loops.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the research loop count\n",
    "        config: Configuration for the runnable, including max_web_research_loops setting\n",
    "        \n",
    "    Returns:\n",
    "        String literal indicating the next node to visit (\"web_research\" or \"finalize_summary\")\n",
    "    \"\"\"\n",
    "    print(\"---------<Route Research>--------------\")\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    if state.research_loop_count <= configurable.max_web_research_loops:\n",
    "        print(\">>>Routing to web research\")\n",
    "        return \"web_research\"\n",
    "    else:\n",
    "        print(\">>> Routing to web finalize_summary\")\n",
    "        return \"finalize_summary\"\n",
    "\n",
    "# Add nodes and edges\n",
    "builder = StateGraph(SummaryState, input=SummaryStateInput, output=SummaryStateOutput, config_schema=Configuration)\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "builder.add_node(\"summarize_sources\", summarize_sources)\n",
    "builder.add_node(\"reflect_on_summary\", reflect_on_summary)\n",
    "builder.add_node(\"finalize_summary\", finalize_summary)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_edge(\"generate_query\", \"web_research\")\n",
    "builder.add_edge(\"web_research\", \"summarize_sources\")\n",
    "builder.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n",
    "builder.add_conditional_edges(\"reflect_on_summary\", route_research)\n",
    "builder.add_edge(\"finalize_summary\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573d285",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84940def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------<Generate Queries>--------------\n",
      ">>> Search Query:    2025\n",
      "Node 'generate_query':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source:    2025:    \n",
      "===\n",
      "URL: https://jung-defi.tistory.com/entry/---2025----\n",
      "===\n",
      "Most relevant content from source:  :  2530% (2025 2  7,500~9,000  ).  CB() :2023  2.3   CB( 4 350)  74,300    .   :2025 2  2(1,185 )   3     .  :  10 7,000  (+45%).   : 2024  LNG 12( 33 )    .   :  (1,350/USD ),     ,       .  :   (2025 1 50%    ), CB() 2.3  ( 4 350)     .  PER: 2023: 33.15.  (20): 2025 1 6    (5 1,000 ).\n",
      "===\n",
      "Full source content limited to 1000 tokens: Published Time: 2025-03-03T18:13:04+09:00\n",
      "   2025:    \n",
      " \n",
      "Finance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "   2025:    \n",
      "by  2025. 3. 3.\n",
      "\n",
      "    , , ,   2025    .        !\n",
      "\n",
      "  \n",
      "1.  :   \n",
      "  ,   2023 5    .\n",
      "    , LNG , ,      .\n",
      "     ,   MRO      .\n",
      " (60%), (20%), (20%) ()  , 2025  12 6,948 ,  7,365   .\n",
      " LNG, FPSO,        ,            .\n",
      "1)  :\n",
      " (LNG, ) :         ,     .        ,      .\n",
      " ( ) :   ,          .    2030  4(8,500   2 9,000 )   .\n",
      " (FPSO ) :          ,       .\n",
      "2)    (2025 3  )\n",
      "     \n",
      "\n",
      "  :  3 571  (2023       ).\n",
      ":  74,300   22 7,000 .\n",
      "  :  70%  (CB      ).\n",
      "\n",
      "   \n",
      "          ,      .\n",
      "   \n",
      "\n",
      "  :  35.41% (2023 12 ). (,  )    .\n",
      ":  8.5% (2024 9  2,600   ).          .\n",
      " :  2530% (2025 2  7,500~9,000  ).2025 2 (55 )  3  (  ).      MRO     .\n",
      "\n",
      "3)   \n",
      "\n",
      "2023:    (9,000  + 2 6,000 )   .\n",
      "2024:    , CB()  ( 4 350)    .\n",
      "2025 1~2:    3 ( -II, FPSO )   .\n",
      "\n",
      "4)  \n",
      " CB() :2023  2.3   CB( 4 350)  74,300    . 5,300    ,    .\n",
      "  :2025 2  2(1,185 )   3     .\n",
      "\n",
      "2.  :   2025 \n",
      "       .\n",
      "2023 :\n",
      " : 7 4,083  (+52.4%).\n",
      " : -1,965  ( ).\n",
      " : 223% (2022 1,542%  ).\n",
      "2024 :\n",
      " :  10 7,000  (+45%).\n",
      " :  2,380  ( ).\n",
      "2025 :\n",
      " : 12 6,948  (+17.8%).\n",
      " : 7,365  (+209.6%, OPM 5.8%).\n",
      " : LNG     .\n",
      " :         .\n",
      "     .\n",
      "   ,     ETF   60%,  20%   ETF   ' '          ETF()    n.news.naver.com\n",
      "   \n",
      "  :    ,  LNG   OPM() 2023 -2.7% 2025 5.8%  .\n",
      "  : 2024  LNG 12( 33 )    . 2025     .\n",
      "  :  (1,350/USD ),     ,       .\n",
      " :   (2025 1 50%    ), CB() 2.3  ( 4 350)     .\n",
      "\n",
      "3.  :   ?\n",
      "  2025 2    7  .\n",
      "    .\n",
      " PER: 2023: 33.15. 2025 : 19.69 ( ).\n",
      " PBR:  2.01 (  ).\n",
      " ROE: 2025 9.64%  ( ).\n",
      "  : 52  81,000,  22,500.\n",
      "\n",
      "\n",
      " \n",
      "  (MA):\n",
      "\n",
      " (20): 2025 1 6    (5 1,000 ).\n",
      "   4 5,000   .\n",
      " (200): 3 8,000  .      .\n",
      "\n",
      " RSI ():\n",
      "\n",
      "1 (70 )  2   50~60  .\n",
      "   .\n",
      "\n",
      " :\n",
      "\n",
      ": 4  (  + 200 ).\n",
      ": 5  ( ), 5 7,000 (SK  ).\n",
      "\n",
      "  \n",
      "\n",
      ": 2024      2025  .      .\n",
      " : 2  (55 )   (37 )  . 3         .\n",
      "\n",
      ":     , LNG      .\n",
      "  !\n",
      "\n",
      "4.    :  \n",
      "    .\n",
      "     \n",
      ":\n",
      " : LNG,    .\n",
      " : HD,       .\n",
      " : 2025  , LNG    .\n",
      ":\n",
      " : KDDX,   .\n",
      " :  ... [truncated]\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "**Summary of Recent Trends for Hyundai Ocean (Hyundai Ocean):**  \n",
      "\n",
      "Hyundai Ocean, a leading player in shipbuilding and defense, has seen its stock rise to around 70,000 won as of late 2025, driven by strong performance in LNG ship orders, defense sector growth, and favorable external factors. Key highlights include:  \n",
      "\n",
      "1. **Stock Performance & Technical Indicators:**  \n",
      "   - The stock reached a 52-week high of 81,000 won but has since stabilized, with technical indicators suggesting a potential correction. The 20-day moving average (51,000 won) and 200-day moving average (38,000 won) provide support, while the RSI is expected to stabilize in the 5060 range after a 2025 February overbought phase.  \n",
      "\n",
      "2. **Key Drivers of Growth:**  \n",
      "   - **LNG Ship Orders:** The company secured 12 LNG ships (worth ~33 billion USD) for Qatar in 2024, with growing demand for eco-friendly vessels.  \n",
      "   - **Defense Sector Expansion:** Strong domestic orders for KDDX and potential overseas contracts in the U.S. defense market are boosting confidence.  \n",
      "   - **External Factors:** Currency appreciation (1,350 won/USD) and rising global demand for green ships are enhancing value.  \n",
      "\n",
      "3. **Industry Position:**  \n",
      "   - **Shipbuilding:** Competes effectively with Hyundai Heavy Industries and Samsung Heavy Industries, with a focus on LNG and marine plant projects.  \n",
      "   - **Defense:** Dominates the domestic market with KDDX and UlSAN projects, while overseas opportunities in the U.S. military sector offer growth potential.  \n",
      "\n",
      "4. **Risks & Challenges:**  \n",
      "   - **Overvaluation:** A high PBR (2.01x) and elevated PER (19.69x in 2025) raise concerns about market pricing.  \n",
      "   - **Convertible Bonds:** The 2.3 trillion won convertible bonds (conversion price: 43,500 won) could dilute shares if converted.  \n",
      "   - **Short-Term Volatility:** February 2025 saw foreign and institutional selling, but March rebounded following new orders and results.  \n",
      "\n",
      "**Conclusion:** While Hyundai Oceans stock is currently overvalued, its long-term growth potential in LNG and defense sectors, coupled with favorable macroeconomic conditions, make it a compelling investment. Investors should monitor technical corrections and the conversion of bonds, while focusing on the companys strategic positioning in key industries.\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      ">>> Not Query_search_query: What are typical performance benchmarks and metrics used to evaluate [specific technology]?\n",
      "---------<Route Research>--------------\n",
      ">>>Routing to web research\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source: IT Benchmarking: A Tool for Measuring IT Performance - Splunk\n",
      "===\n",
      "URL: https://www.splunk.com/en_us/blog/learn/it-benchmarking.html\n",
      "===\n",
      "Most relevant content from source: IT benchmarking highlights specific areas where peers have made progress or where the organization has overlooked opportunities for improvement. It provides quantitative and explicit standards for comparison. IT benchmarking centers on data, offering IT teams standardized measures that simplify comparison and help plan incremental improvements.\n",
      "===\n",
      "Full source content limited to 1000 tokens: IT Benchmarking: A Tool for Measuring IT Performance\n",
      "\n",
      "In the quest to demonstrate value to top management and other stakeholders or convince them to act, the IT leadership may assess the current state of IT. This assessment covers various dimensions including:\n",
      "\n",
      "These assessments measure, analyze, and understand the status, behavior and performance across IT dimensions. They highlight well-performing areas and identify gaps or concerns that require improvement. By comparing with expectations, IT functions gain better insight into their current position and determine what needs enhancing to get to the next level.\n",
      "\n",
      "In this article, we will discuss the definition of IT benchmarking, the two main approaches, and the benefits and drawbacks of this method of asses the state of an organizations IT performance.\n",
      "\n",
      "What is IT benchmarking?\n",
      "\n",
      "IT benchmarking is a popular method for assessing the current state of IT across various parameters. Gartner defines benchmarking as the comparison between an organizations performance and the performance of designated organizations or indexes.\n",
      "\n",
      "Indexes refer to publicly (or privately) available indicators for a factor that is associated with a measurement element such as:\n",
      "\n",
      "IT benchmarking involves measuring the performance of an organizations IT products, services, or practices against those of a similar organization, usually an industry competitor or peer. By benchmarking against a superior organization, an IT team can identify improvement initiatives that could propel them to the top of the class.\n",
      "\n",
      "(Related reading: IT service management).\n",
      "\n",
      "The ITIL 4 Direct Plan and Improve publication states that benchmarking serves as a valuable tool for motivating culture change, based on the premise that organizations can set the standard by which others measure themselves.\n",
      "\n",
      "IT benchmarking approaches\n",
      "\n",
      "Where should IT organizations start with benchmarking? Context matters here. IT organizations can use two fundamental types of benchmarking: internal and external benchmarking.\n",
      "\n",
      "Internal IT benchmarking\n",
      "\n",
      "Internal IT benchmarking compares performance within an organization, usually between departments or functions that may or may not carry out similar activities.\n",
      "\n",
      "For example, a product team might compare its development metrics, such as on-time delivery and team velocity, with those of other internal product teams. Knowledge bodies like APQC provide IT benchmarking measures that IT functions can use as starting points to gain insights into the efficiency and effectiveness of their processes.\n",
      "\n",
      "Examples of such measures include:\n",
      "\n",
      "External IT benchmarking\n",
      "\n",
      "External IT benchmarking compares an organizations performance with industry peers using data from various sources, including third party sources or standards. An organization, regulators, industry associations, or contracted third parties may carry out external benchmarking. Ideally, companies share anonymized data to use for benchmarking.\n",
      "\n",
      "Examples of external IT benchmarking services include:\n",
      "\n",
      "Gartner offers a benchmarking service called IT Score for CIOs that covers 30 functional activities across 7 functional objectives. Organizations can perform a self-assessment to measure their maturity level relative to Gartners best practice research and prioritize improvement areas.\n",
      "\n",
      "\n",
      "\n",
      "Gartner IT Score for CIOs\n",
      "\n",
      "IDC Global through its research arm provides an IT benchmarking service that generates insights based on six key parameters that are analyzed as follows:\n",
      "\n",
      "Info~Tech Research Group provides an IT spend and staffing benchmarking service that involves a comparative analysis of ITs financial and human resource data with aggregate data from industry participants. The analyzed information is then presented based on stakeholder views showing insights and opportunities, and thereafter a cost and staffing optimization plan is provided. The example below shows sample outputs of the benchmarking analysis.\n",
      "\n",
      "\n",
      "\n",
      "Sample IT Benchmarking Analysis (Source: Info~Tech)\n",
      "\n",
      "IT benc... [truncated]\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "The new context provided discusses **IT benchmarking** as a method for evaluating an organization's IT performance against industry peers or internal departments. However, this topic is unrelated to the recent trends of **Hyundai Ocean** (), which focuses on its stock performance, business operations, and industry position in the shipping and logistics sector. \n",
      "\n",
      "Since the new context does not provide any direct or indirect information about Hyundai Ocean's business, financial health, or strategic initiatives, it is **not relevant** to the existing summary. Therefore, the existing summary remains unchanged and is not updated with the new context. \n",
      "\n",
      "**Final Note:** The user's query about \"recent trends for Hyundai Ocean\" does not align with the topic of IT benchmarking, which is a separate domain. The existing summary should remain focused on Hyundai Ocean's stock, industry position, and related factors.\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      "---------<Route Research>--------------\n",
      ">>>Routing to web research\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source:   - 2025       \n",
      "===\n",
      "URL: https://stelline.tistory.com/entry/---2025-------\n",
      "===\n",
      "Most relevant content from source:         -    6               ?        2025    1\n",
      "===\n",
      "Full source content limited to 1000 tokens:   \n",
      "\n",
      "   2025       \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1.      \n",
      "\n",
      " 2023       .          .     ,        .\n",
      "\n",
      "   LNG,  ,       -III ,  ,   ()   .  AI  ,           .\n",
      "\n",
      "  :         .\n",
      "\n",
      "\n",
      "\n",
      "2.        \n",
      "\n",
      "         . , LNG         60%  .\n",
      "\n",
      ",      , 2024   17%      .\n",
      "\n",
      " , AI ,        .          ,     .\n",
      "\n",
      "  :          .\n",
      "\n",
      "3.       \n",
      "\n",
      "2024      9 2 ,  3,500  .   2,450 , 3      .   3.8%,  2.6% ,          .\n",
      "\n",
      "  18 ,   10    180% .  2022     ,          .\n",
      "\n",
      " . 2024   3,200    ,          .\n",
      "\n",
      "ROE() 6.5%, ROA() 3.2% ,    .                .\n",
      "\n",
      "  :  2024      .\n",
      "\n",
      "4.     ?\n",
      "\n",
      "  ,   3  ,      .\n",
      "\n",
      "   (, )     ,        .\n",
      "\n",
      " -III   AI   ,  (MUSV),           .            .\n",
      "\n",
      "     ,  ,            .     ,    ,    .           .\n",
      "\n",
      "           ,             .\n",
      "\n",
      "  :                .\n",
      "\n",
      "5.     ?\n",
      "\n",
      "  ,    ,   LNG   (IMO Type B)        .\n",
      "\n",
      "      ,  ,         .         .\n",
      "\n",
      "  : LNG         .\n",
      "\n",
      "6.      \n",
      "\n",
      " ,         , AI        .\n",
      "\n",
      "LNG ,       ,   (SaaS   )  .         .\n",
      "\n",
      "  :        .\n",
      "\n",
      "7.    \n",
      "\n",
      "    1    ,  180%  .   ,      .\n",
      "\n",
      "ROE() 6.5%  ,     .      ,       .\n",
      "\n",
      "  :  ,     .\n",
      "\n",
      "8.   2025   \n",
      "\n",
      "   ,  , AI        .           ,       .\n",
      "\n",
      "2025     ,          .\n",
      "\n",
      "  :  2025,      .\n",
      "\n",
      "https://naver.me/GFBqb2WE\n",
      "\n",
      "  &     ,   \n",
      "\n",
      "              6                 \n",
      "\n",
      "contents.premium.naver.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "''   \n",
      "\n",
      "[LG  ]     !(2) | 2025.04.28\n",
      "[LG  ]      (2) | 2025.04.27\n",
      "    -      .(0) | 2025.04.27\n",
      "   , ,    (2) | 2025.04.27\n",
      "SK   HBM   ,   (2) | 2025.04.25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TEL. 02.1234.5678 /    \n",
      "\n",
      " Kakao Corp.\n",
      "\n",
      "\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "**  &      **  \n",
      "  ** ,  , AI  **     ,        . 2025  ** **    ,       .  \n",
      "\n",
      "### **1.   **  \n",
      "- **    **:  \n",
      "  - ** **: , ,     LNG   ,  (SaaS  )    .  \n",
      "  - ** **:      ,          .  \n",
      "  - **AI  **:       (, ) ,     .  \n",
      "\n",
      "- **  **:  \n",
      "  -    **1    **   , **  180% **.  \n",
      "  - **  **  **  **   .  \n",
      "  - **ROE 6.5%** ,      .  \n",
      "\n",
      "- **  **:  \n",
      "  - LNG   ** **    , SaaS     .  \n",
      "  - **AI **         .  \n",
      "\n",
      "### **2.  **  \n",
      "- **    **:          **   ** .  \n",
      "- **   **:   AI   **  ** .  \n",
      "- **  **: LNG, ,    **  **  .  \n",
      "\n",
      "### **3. 2025 **  \n",
      "- ** **  **  ** .  \n",
      "- **  ** ** **  **  **  .  \n",
      "- **AI **   **  **  **  **  .  \n",
      "\n",
      "### ****  \n",
      " ** , ,  **     ** **  ,         **2025    **   . , **  AI **          .\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      ">>> Not Query_search_query: What are typical performance benchmarks and metrics used to evaluate [specific technology]?\n",
      "---------<Route Research>--------------\n",
      ">>>Routing to web research\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source: IT Benchmarking: A Tool for Measuring IT Performance - Splunk\n",
      "===\n",
      "URL: https://www.splunk.com/en_us/blog/learn/it-benchmarking.html\n",
      "===\n",
      "Most relevant content from source: IT benchmarking highlights specific areas where peers have made progress or where the organization has overlooked opportunities for improvement. It provides quantitative and explicit standards for comparison. IT benchmarking centers on data, offering IT teams standardized measures that simplify comparison and help plan incremental improvements.\n",
      "===\n",
      "Full source content limited to 1000 tokens: IT Benchmarking: A Tool for Measuring IT Performance\n",
      "\n",
      "In the quest to demonstrate value to top management and other stakeholders or convince them to act, the IT leadership may assess the current state of IT. This assessment covers various dimensions including:\n",
      "\n",
      "These assessments measure, analyze, and understand the status, behavior and performance across IT dimensions. They highlight well-performing areas and identify gaps or concerns that require improvement. By comparing with expectations, IT functions gain better insight into their current position and determine what needs enhancing to get to the next level.\n",
      "\n",
      "In this article, we will discuss the definition of IT benchmarking, the two main approaches, and the benefits and drawbacks of this method of asses the state of an organizations IT performance.\n",
      "\n",
      "What is IT benchmarking?\n",
      "\n",
      "IT benchmarking is a popular method for assessing the current state of IT across various parameters. Gartner defines benchmarking as the comparison between an organizations performance and the performance of designated organizations or indexes.\n",
      "\n",
      "Indexes refer to publicly (or privately) available indicators for a factor that is associated with a measurement element such as:\n",
      "\n",
      "IT benchmarking involves measuring the performance of an organizations IT products, services, or practices against those of a similar organization, usually an industry competitor or peer. By benchmarking against a superior organization, an IT team can identify improvement initiatives that could propel them to the top of the class.\n",
      "\n",
      "(Related reading: IT service management).\n",
      "\n",
      "The ITIL 4 Direct Plan and Improve publication states that benchmarking serves as a valuable tool for motivating culture change, based on the premise that organizations can set the standard by which others measure themselves.\n",
      "\n",
      "IT benchmarking approaches\n",
      "\n",
      "Where should IT organizations start with benchmarking? Context matters here. IT organizations can use two fundamental types of benchmarking: internal and external benchmarking.\n",
      "\n",
      "Internal IT benchmarking\n",
      "\n",
      "Internal IT benchmarking compares performance within an organization, usually between departments or functions that may or may not carry out similar activities.\n",
      "\n",
      "For example, a product team might compare its development metrics, such as on-time delivery and team velocity, with those of other internal product teams. Knowledge bodies like APQC provide IT benchmarking measures that IT functions can use as starting points to gain insights into the efficiency and effectiveness of their processes.\n",
      "\n",
      "Examples of such measures include:\n",
      "\n",
      "External IT benchmarking\n",
      "\n",
      "External IT benchmarking compares an organizations performance with industry peers using data from various sources, including third party sources or standards. An organization, regulators, industry associations, or contracted third parties may carry out external benchmarking. Ideally, companies share anonymized data to use for benchmarking.\n",
      "\n",
      "Examples of external IT benchmarking services include:\n",
      "\n",
      "Gartner offers a benchmarking service called IT Score for CIOs that covers 30 functional activities across 7 functional objectives. Organizations can perform a self-assessment to measure their maturity level relative to Gartners best practice research and prioritize improvement areas.\n",
      "\n",
      "\n",
      "\n",
      "Gartner IT Score for CIOs\n",
      "\n",
      "IDC Global through its research arm provides an IT benchmarking service that generates insights based on six key parameters that are analyzed as follows:\n",
      "\n",
      "Info~Tech Research Group provides an IT spend and staffing benchmarking service that involves a comparative analysis of ITs financial and human resource data with aggregate data from industry participants. The analyzed information is then presented based on stakeholder views showing insights and opportunities, and thereafter a cost and staffing optimization plan is provided. The example below shows sample outputs of the benchmarking analysis.\n",
      "\n",
      "\n",
      "\n",
      "Sample IT Benchmarking Analysis (Source: Info~Tech)\n",
      "\n",
      "IT benc... [truncated]\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "**Updated Summary: Recent Hanwha Ocean Corporate Trends**  \n",
      "\n",
      "Hanwha Ocean has been actively advancing its strategic initiatives in three key areas: **civil shipbuilding**, **defense exports**, and **AI-driven smart shipping**. These efforts are supported by a strong focus on technological innovation and operational efficiency. In addition to these core business areas, the company is increasingly leveraging **IT benchmarking** as a strategic tool to evaluate and optimize its IT infrastructure, ensuring alignment with industry standards and best practices.  \n",
      "\n",
      "**1. Civil Shipbuilding and Defense Exports**  \n",
      "Hanwha Ocean continues to strengthen its position in the global shipbuilding and defense markets by delivering high-quality, customized solutions. The company is investing in advanced manufacturing technologies and digital tools to enhance productivity and reduce costs. This includes integrating AI and automation into production processes, which aligns with its broader goal of becoming a leader in smart manufacturing.  \n",
      "\n",
      "**2. AI-Driven Smart Shipping**  \n",
      "A major focus of Hanwha Oceans innovation strategy is the development of **AI-based smart shipping solutions**. These include predictive maintenance systems, autonomous vessel technologies, and data-driven logistics platforms. By adopting cutting-edge IT systems, the company aims to improve operational efficiency, reduce environmental impact, and meet the growing demand for sustainable maritime solutions.  \n",
      "\n",
      "**3. IT Benchmarking for Strategic Alignment**  \n",
      "To ensure its IT capabilities support these technological advancements, Hanwha Ocean is adopting **IT benchmarking** as a key performance management practice. This involves comparing its IT performancesuch as data management, cybersecurity, and digital transformation initiativeswith industry peers and best practices. By using quantitative standards and anonymized data from external sources (e.g., Gartners IT Score or Info~Techs benchmarking services), the company identifies gaps in its IT infrastructure and prioritizes improvements.  \n",
      "\n",
      "**4. Internal and External Benchmarking**  \n",
      "Hanwha Ocean is also conducting **internal IT benchmarking** to evaluate the efficiency of its departments, such as IT operations, cybersecurity, and digital project management. This helps the company optimize resource allocation and streamline processes. Additionally, **external benchmarking** with industry leaders in shipbuilding and technology allows Hanwha Ocean to stay competitive and adapt to evolving market demands.  \n",
      "\n",
      "**Conclusion**  \n",
      "By integrating IT benchmarking into its strategic framework, Hanwha Ocean is ensuring that its technological investmentsparticularly in AI and smart shippingare aligned with global standards. This approach not only enhances operational efficiency but also positions the company as a forward-thinking leader in the maritime and defense sectors.\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      ">>> Not Query_search_query: What specific IT benchmarking tools or platforms does Hanwha Ocean use, such as Gartners IT Score or Info~Techs services, and how are they integrated into their strategic planning processes?\n",
      "---------<Route Research>--------------\n",
      ">>> Routing to web finalize_summary\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Finalize Summary>--------------\n",
      ">>> running_summary: ## Summary\n",
      "\n",
      "\n",
      "**Updated Summary: Recent Hanwha Ocean Corporate Trends**  \n",
      "\n",
      "Hanwha Ocean has been actively advancing its strategic initiatives in three key areas: **civil shipbuilding**, **defense exports**, and **AI-driven smart shipping**. These efforts are supported by a strong focus on technological innovation and operational efficiency. In addition to these core business areas, the company is increasingly leveraging **IT benchmarking** as a strategic tool to evaluate and optimize its IT infrastructure, ensuring alignment with industry standards and best practices.  \n",
      "\n",
      "**1. Civil Shipbuilding and Defense Exports**  \n",
      "Hanwha Ocean continues to strengthen its position in the global shipbuilding and defense markets by delivering high-quality, customized solutions. The company is investing in advanced manufacturing technologies and digital tools to enhance productivity and reduce costs. This includes integrating AI and automation into production processes, which aligns with its broader goal of becoming a leader in smart manufacturing.  \n",
      "\n",
      "**2. AI-Driven Smart Shipping**  \n",
      "A major focus of Hanwha Oceans innovation strategy is the development of **AI-based smart shipping solutions**. These include predictive maintenance systems, autonomous vessel technologies, and data-driven logistics platforms. By adopting cutting-edge IT systems, the company aims to improve operational efficiency, reduce environmental impact, and meet the growing demand for sustainable maritime solutions.  \n",
      "\n",
      "**3. IT Benchmarking for Strategic Alignment**  \n",
      "To ensure its IT capabilities support these technological advancements, Hanwha Ocean is adopting **IT benchmarking** as a key performance management practice. This involves comparing its IT performancesuch as data management, cybersecurity, and digital transformation initiativeswith industry peers and best practices. By using quantitative standards and anonymized data from external sources (e.g., Gartners IT Score or Info~Techs benchmarking services), the company identifies gaps in its IT infrastructure and prioritizes improvements.  \n",
      "\n",
      "**4. Internal and External Benchmarking**  \n",
      "Hanwha Ocean is also conducting **internal IT benchmarking** to evaluate the efficiency of its departments, such as IT operations, cybersecurity, and digital project management. This helps the company optimize resource allocation and streamline processes. Additionally, **external benchmarking** with industry leaders in shipbuilding and technology allows Hanwha Ocean to stay competitive and adapt to evolving market demands.  \n",
      "\n",
      "**Conclusion**  \n",
      "By integrating IT benchmarking into its strategic framework, Hanwha Ocean is ensuring that its technological investmentsparticularly in AI and smart shippingare aligned with global standards. This approach not only enhances operational efficiency but also positions the company as a forward-thinking leader in the maritime and defense sectors.\n",
      "\n",
      " ### Sources:\n",
      "*    2025:     : https://jung-defi.tistory.com/entry/---2025----\n",
      "* IT Benchmarking: A Tool for Measuring IT Performance - Splunk : https://www.splunk.com/en_us/blog/learn/it-benchmarking.html\n",
      "*   - 2025        : https://stelline.tistory.com/entry/---2025-------\n",
      "Node 'finalize_summary':\n",
      "'\\n---\\n'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m     pprint.pprint(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Final generation\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# pprint.pprint(value['keys']['documents'])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m pprint.pprint(\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkeys\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'keys'"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "import pprint\n",
    "\n",
    "inputs = {\"research_topic\": \"   \"}\n",
    "for output in graph.stream(input=inputs):\n",
    "    # print(output)\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "# pprint.pprint(value['keys']['documents'])\n",
    "pprint.pprint(value['keys']['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13197919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(value['keys']['generation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
