{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97e66be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16128bb",
   "metadata": {},
   "source": [
    "# State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c40930e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from dataclasses import dataclass, field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryState:\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "    search_query: str = field(default=None) # Search query\n",
    "    web_research_results: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    sources_gathered: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    research_loop_count: int = field(default=0) # Research loop count\n",
    "    running_summary: str = field(default=None) # Final report\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateInput:\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateOutput:\n",
    "    running_summary: str = field(default=None) # Final report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf50772",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e26adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Optional, Literal\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "class SearchAPI(Enum):\n",
    "    PERPLEXITY = \"perplexity\"\n",
    "    TAVILY = \"tavily\"\n",
    "    DUCKDUCKGO = \"duckduckgo\"\n",
    "    SEARXNG = \"searxng\"\n",
    "\n",
    "class Configuration(BaseModel):\n",
    "    \"\"\"The configurable fields for the research assistant.\"\"\"\n",
    "\n",
    "    max_web_research_loops: int = Field(\n",
    "        default=3,\n",
    "        title=\"Research Depth\",\n",
    "        description=\"Number of research iterations to perform\"\n",
    "    )\n",
    "    local_llm: str = Field(\n",
    "        default=\"qwen3:4b\",\n",
    "        title=\"LLM Model Name\",\n",
    "        description=\"Name of the LLM model to use\"\n",
    "    )\n",
    "    llm_provider: Literal[\"ollama\", \"lmstudio\"] = Field(\n",
    "        default=\"ollama\",\n",
    "        title=\"LLM Provider\",\n",
    "        description=\"Provider for the LLM (Ollama or LMStudio)\"\n",
    "    )\n",
    "    search_api: Literal[\"perplexity\", \"tavily\", \"duckduckgo\", \"searxng\"] = Field(\n",
    "        default=\"tavily\",\n",
    "        title=\"Search API\",\n",
    "        description=\"Web search API to use\"\n",
    "    )\n",
    "    fetch_full_page: bool = Field(\n",
    "        default=True,\n",
    "        title=\"Fetch Full Page\",\n",
    "        description=\"Include the full page content in the search results\"\n",
    "    )\n",
    "    ollama_base_url: str = Field(\n",
    "        default=\"http://localhost:11434/\",\n",
    "        title=\"Ollama Base URL\",\n",
    "        description=\"Base URL for Ollama API\"\n",
    "    )\n",
    "    lmstudio_base_url: str = Field(\n",
    "        default=\"http://localhost:1234/v1\",\n",
    "        title=\"LMStudio Base URL\",\n",
    "        description=\"Base URL for LMStudio OpenAI-compatible API\"\n",
    "    )\n",
    "    strip_thinking_tokens: bool = Field(\n",
    "        default=True,\n",
    "        title=\"Strip Thinking Tokens\",\n",
    "        description=\"Whether to strip <think> tokens from model responses\"\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "        \n",
    "        # Get raw values from environment or config\n",
    "        raw_values: dict[str, Any] = {\n",
    "            name: os.environ.get(name.upper(), configurable.get(name))\n",
    "            for name in cls.model_fields.keys()\n",
    "        }\n",
    "        \n",
    "        # Filter out None values\n",
    "        values = {k: v for k, v in raw_values.items() if v is not None}\n",
    "        \n",
    "        return cls(**values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc59361",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb1a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import requests\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "\n",
    "from markdownify import markdownify\n",
    "from langsmith import traceable\n",
    "from tavily import TavilyClient\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "from langchain_community.utilities import SearxSearchWrapper\n",
    "\n",
    "def get_config_value(value: Any) -> str:\n",
    "    \"\"\"\n",
    "    Convert configuration values to string format, handling both string and enum types.\n",
    "    \n",
    "    Args:\n",
    "        value (Any): The configuration value to process. Can be a string or an Enum.\n",
    "    \n",
    "    Returns:\n",
    "        str: The string representation of the value.\n",
    "        \n",
    "    Examples:\n",
    "        >>> get_config_value(\"tavily\")\n",
    "        'tavily'\n",
    "        >>> get_config_value(SearchAPI.TAVILY)\n",
    "        'tavily'\n",
    "    \"\"\"\n",
    "    return value if isinstance(value, str) else value.value\n",
    "\n",
    "def strip_thinking_tokens(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove <think> and </think> tags and their content from the text.\n",
    "    \n",
    "    Iteratively removes all occurrences of content enclosed in thinking tokens.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to process\n",
    "        \n",
    "    Returns:\n",
    "        str: The text with thinking tokens and their content removed\n",
    "    \"\"\"\n",
    "    while \"<think>\" in text and \"</think>\" in text:\n",
    "        start = text.find(\"<think>\")\n",
    "        end = text.find(\"</think>\") + len(\"</think>\")\n",
    "        text = text[:start] + text[end:]\n",
    "    return text\n",
    "\n",
    "def deduplicate_and_format_sources(\n",
    "    search_response: Union[Dict[str, Any], List[Dict[str, Any]]], \n",
    "    max_tokens_per_source: int, \n",
    "    fetch_full_page: bool = False\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Format and deduplicate search responses from various search APIs.\n",
    "    \n",
    "    Takes either a single search response or list of responses from search APIs,\n",
    "    deduplicates them by URL, and formats them into a structured string.\n",
    "    \n",
    "    Args:\n",
    "        search_response (Union[Dict[str, Any], List[Dict[str, Any]]]): Either:\n",
    "            - A dict with a 'results' key containing a list of search results\n",
    "            - A list of dicts, each containing search results\n",
    "        max_tokens_per_source (int): Maximum number of tokens to include for each source's content\n",
    "        fetch_full_page (bool, optional): Whether to include the full page content. Defaults to False.\n",
    "            \n",
    "    Returns:\n",
    "        str: Formatted string with deduplicated sources\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If input is neither a dict with 'results' key nor a list of search results\n",
    "    \"\"\"\n",
    "    # Convert input to list of results\n",
    "    if isinstance(search_response, dict):\n",
    "        sources_list = search_response['results']\n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                sources_list.extend(response['results'])\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "    \n",
    "    # Deduplicate by URL\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        if source['url'] not in unique_sources:\n",
    "            unique_sources[source['url']] = source\n",
    "    \n",
    "    # Format output\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"Source: {source['title']}\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if fetch_full_page:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "                \n",
    "    return formatted_text.strip()\n",
    "\n",
    "def format_sources(search_results: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Format search results into a bullet-point list of sources with URLs.\n",
    "    \n",
    "    Creates a simple bulleted list of search results with title and URL for each source.\n",
    "    \n",
    "    Args:\n",
    "        search_results (Dict[str, Any]): Search response containing a 'results' key with\n",
    "                                        a list of search result objects\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string with sources as bullet points in the format \"* title : url\"\n",
    "    \"\"\"\n",
    "    return '\\n'.join(\n",
    "        f\"* {source['title']} : {source['url']}\"\n",
    "        for source in search_results['results']\n",
    "    )\n",
    "\n",
    "def fetch_raw_content(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch HTML content from a URL and convert it to markdown format.\n",
    "    \n",
    "    Uses a 10-second timeout to avoid hanging on slow sites or large pages.\n",
    "    \n",
    "    Args:\n",
    "        url (str): The URL to fetch content from\n",
    "        \n",
    "    Returns:\n",
    "        Optional[str]: The fetched content converted to markdown if successful,\n",
    "                      None if any error occurs during fetching or conversion\n",
    "    \"\"\"\n",
    "    try:                \n",
    "        # Create a client with reasonable timeout\n",
    "        with httpx.Client(timeout=10.0) as client:\n",
    "            response = client.get(url)\n",
    "            response.raise_for_status()\n",
    "            return markdownify(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to fetch full page content for {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "@traceable\n",
    "def duckduckgo_search(query: str, max_results: int = 3, fetch_full_page: bool = False) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Search the web using DuckDuckGo and return formatted results.\n",
    "    \n",
    "    Uses the DDGS library to perform web searches through DuckDuckGo.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        max_results (int, optional): Maximum number of results to return. Defaults to 3.\n",
    "        fetch_full_page (bool, optional): Whether to fetch full page content from result URLs. \n",
    "                                         Defaults to False.\n",
    "    Returns:\n",
    "        Dict[str, List[Dict[str, Any]]]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str or None): Full page content if fetch_full_page is True,\n",
    "                                            otherwise same as content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with DDGS() as ddgs:\n",
    "            results = []\n",
    "            search_results = list(ddgs.text(query, max_results=max_results))\n",
    "            \n",
    "            for r in search_results:\n",
    "                url = r.get('href')\n",
    "                title = r.get('title')\n",
    "                content = r.get('body')\n",
    "                \n",
    "                if not all([url, title, content]):\n",
    "                    print(f\"Warning: Incomplete result from DuckDuckGo: {r}\")\n",
    "                    continue\n",
    "\n",
    "                raw_content = content\n",
    "                if fetch_full_page:\n",
    "                    raw_content = fetch_raw_content(url)\n",
    "                \n",
    "                # Add result to list\n",
    "                result = {\n",
    "                    \"title\": title,\n",
    "                    \"url\": url,\n",
    "                    \"content\": content,\n",
    "                    \"raw_content\": raw_content\n",
    "                }\n",
    "                results.append(result)\n",
    "            \n",
    "            return {\"results\": results}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DuckDuckGo search: {str(e)}\")\n",
    "        print(f\"Full error details: {type(e).__name__}\")\n",
    "        return {\"results\": []}\n",
    "\n",
    "@traceable\n",
    "def searxng_search(query: str, max_results: int = 3, fetch_full_page: bool = False) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Search the web using SearXNG and return formatted results.\n",
    "    \n",
    "    Uses the SearxSearchWrapper to perform searches through a SearXNG instance.\n",
    "    The SearXNG host URL is read from the SEARXNG_URL environment variable\n",
    "    or defaults to http://localhost:8888.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        max_results (int, optional): Maximum number of results to return. Defaults to 3.\n",
    "        fetch_full_page (bool, optional): Whether to fetch full page content from result URLs.\n",
    "                                         Defaults to False.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List[Dict[str, Any]]]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str or None): Full page content if fetch_full_page is True,\n",
    "                                           otherwise same as content\n",
    "    \"\"\"\n",
    "    host=os.environ.get(\"SEARXNG_URL\", \"http://localhost:8888\")\n",
    "    s = SearxSearchWrapper(searx_host=host)\n",
    "\n",
    "    results = []\n",
    "    search_results = s.results(query, num_results=max_results)\n",
    "    for r in search_results:\n",
    "        url = r.get('link')\n",
    "        title = r.get('title')\n",
    "        content = r.get('snippet')\n",
    "        \n",
    "        if not all([url, title, content]):\n",
    "            print(f\"Warning: Incomplete result from SearXNG: {r}\")\n",
    "            continue\n",
    "\n",
    "        raw_content = content\n",
    "        if fetch_full_page:\n",
    "            raw_content = fetch_raw_content(url)\n",
    "        \n",
    "        # Add result to list\n",
    "        result = {\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"content\": content,\n",
    "            \"raw_content\": raw_content\n",
    "        }\n",
    "        results.append(result)\n",
    "    return {\"results\": results}\n",
    "    \n",
    "@traceable\n",
    "def tavily_search(query: str, fetch_full_page: bool = True, max_results: int = 3) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Search the web using the Tavily API and return formatted results.\n",
    "    \n",
    "    Uses the TavilyClient to perform searches. Tavily API key must be configured\n",
    "    in the environment.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        fetch_full_page (bool, optional): Whether to include raw content from sources.\n",
    "                                         Defaults to True.\n",
    "        max_results (int, optional): Maximum number of results to return. Defaults to 3.\n",
    "        \n",
    "    Returns:\n",
    "        Dict[str, List[Dict[str, Any]]]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str or None): Full content of the page if available and \n",
    "                                            fetch_full_page is True\n",
    "    \"\"\"\n",
    "     \n",
    "    tavily_client = TavilyClient()\n",
    "    return tavily_client.search(query, \n",
    "                         max_results=max_results, \n",
    "                         include_raw_content=fetch_full_page)\n",
    "\n",
    "@traceable\n",
    "def perplexity_search(query: str, perplexity_search_loop_count: int = 0) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Search the web using the Perplexity API and return formatted results.\n",
    "    \n",
    "    Uses the Perplexity API to perform searches with the 'sonar-pro' model.\n",
    "    Requires a PERPLEXITY_API_KEY environment variable to be set.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        perplexity_search_loop_count (int, optional): The loop step for perplexity search\n",
    "                                                     (used for source labeling). Defaults to 0.\n",
    "  \n",
    "    Returns:\n",
    "        Dict[str, Any]: Search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result (includes search counter)\n",
    "                - url (str): URL of the citation source\n",
    "                - content (str): Content of the response or reference to main content\n",
    "                - raw_content (str or None): Full content for the first source, None for additional\n",
    "                                            citation sources\n",
    "                                            \n",
    "    Raises:\n",
    "        requests.exceptions.HTTPError: If the API request fails\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.getenv('PERPLEXITY_API_KEY')}\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"sonar-pro\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Search the web and provide factual information with sources.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        \"https://api.perplexity.ai/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    response.raise_for_status()  # Raise exception for bad status codes\n",
    "    \n",
    "    # Parse the response\n",
    "    data = response.json()\n",
    "    content = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # Perplexity returns a list of citations for a single search result\n",
    "    citations = data.get(\"citations\", [\"https://perplexity.ai\"])\n",
    "    \n",
    "    # Return first citation with full content, others just as references\n",
    "    results = [{\n",
    "        \"title\": f\"Perplexity Search {perplexity_search_loop_count + 1}, Source 1\",\n",
    "        \"url\": citations[0],\n",
    "        \"content\": content,\n",
    "        \"raw_content\": content\n",
    "    }]\n",
    "    \n",
    "    # Add additional citations without duplicating content\n",
    "    for i, citation in enumerate(citations[1:], start=2):\n",
    "        results.append({\n",
    "            \"title\": f\"Perplexity Search {perplexity_search_loop_count + 1}, Source {i}\",\n",
    "            \"url\": citation,\n",
    "            \"content\": \"See above for full content\",\n",
    "            \"raw_content\": None\n",
    "        })\n",
    "    \n",
    "    return {\"results\": results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456cb91",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9b3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get current date in a readable format\n",
    "def get_current_date():\n",
    "    return datetime.now().strftime(\"%B %d, %Y\")\n",
    "\n",
    "query_writer_instructions=\"\"\"Your goal is to generate a targeted web search query.\n",
    "\n",
    "<CONTEXT>\n",
    "Current date: {current_date}\n",
    "Please ensure your queries account for the most current information available as of this date.\n",
    "</CONTEXT>\n",
    "\n",
    "<TOPIC>\n",
    "{research_topic}\n",
    "</TOPIC>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with ALL three of these exact keys:\n",
    "   - \"query\": The actual search query string\n",
    "   - \"rationale\": Brief explanation of why this query is relevant\n",
    "</FORMAT>\n",
    "\n",
    "<EXAMPLE>\n",
    "Example output:\n",
    "{{\n",
    "    \"query\": \"machine learning transformer architecture explained\",\n",
    "    \"rationale\": \"Understanding the fundamental structure of transformer models\"\n",
    "}}\n",
    "</EXAMPLE>\n",
    "\n",
    "Provide your response in JSON format:\"\"\"\n",
    "\n",
    "summarizer_instructions=\"\"\"\n",
    "<GOAL>\n",
    "Generate a high-quality summary of the provided context.\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant information related to the user topic from the search results\n",
    "2. Ensure a coherent flow of information\n",
    "\n",
    "When EXTENDING an existing summary:                                                                                                                 \n",
    "1. Read the existing summary and new search results carefully.                                                    \n",
    "2. Compare the new information with the existing summary.                                                         \n",
    "3. For each piece of new information:                                                                             \n",
    "    a. If it's related to existing points, integrate it into the relevant paragraph.                               \n",
    "    b. If it's entirely new but relevant, add a new paragraph with a smooth transition.                            \n",
    "    c. If it's not relevant to the user topic, skip it.                                                            \n",
    "4. Ensure all additions are relevant to the user's topic.                                                         \n",
    "5. Verify that your final output differs from the input summary.                                                                                                                                                            \n",
    "< /REQUIREMENTS >\n",
    "\n",
    "< FORMATTING >\n",
    "- Start directly with the updated summary, without preamble or titles. Do not use XML tags in the output.  \n",
    "< /FORMATTING >\n",
    "\n",
    "<Task>\n",
    "Think carefully about the provided Context first. Then generate a summary of the context to address the User Input.\n",
    "</Task>\n",
    "\"\"\"\n",
    "\n",
    "reflection_instructions = \"\"\"You are an expert research assistant analyzing a summary about {research_topic}.\n",
    "\n",
    "<GOAL>\n",
    "1. Identify knowledge gaps or areas that need deeper exploration\n",
    "2. Generate a follow-up question that would help expand your understanding\n",
    "3. Focus on technical details, implementation specifics, or emerging trends that weren't fully covered\n",
    "</GOAL>\n",
    "\n",
    "<REQUIREMENTS>\n",
    "Ensure the follow-up question is self-contained and includes necessary context for web search.\n",
    "</REQUIREMENTS>\n",
    "\n",
    "<FORMAT>\n",
    "Format your response as a JSON object with these exact keys:\n",
    "- knowledge_gap: Describe what information is missing or needs clarification\n",
    "- follow_up_query: Write a specific question to address this gap\n",
    "</FORMAT>\n",
    "\n",
    "<Task>\n",
    "Reflect carefully on the Summary to identify knowledge gaps and produce a follow-up query. Then, produce your output following this JSON format:\n",
    "{{\n",
    "    \"knowledge_gap\": \"The summary lacks information about performance metrics and benchmarks\",\n",
    "    \"follow_up_query\": \"What are typical performance benchmarks and metrics used to evaluate [specific technology]?\"\n",
    "}}\n",
    "</Task>\n",
    "\n",
    "Provide your analysis in JSON format:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0432293d",
   "metadata": {},
   "source": [
    "# Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9cb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# api_key=os.environ.get(\"openrouter_api_key\")\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     model = \"qwen/qwen3-14b:free\", # \"qwen/qwen3-14b:free\", \"qwen/qwen3-30b-a3b:free\",\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=api_key,\n",
    "#     temperature=0,\n",
    "#     )\n",
    "\n",
    "# llm_json_mode = ChatOpenAI(\n",
    "#     model = \"qwen/qwen3-14b:free\", # \"qwen/qwen3-14b:free\", \"qwen/qwen3-30b-a3b:free\",\n",
    "#     base_url=\"https://openrouter.ai/api/v1\",\n",
    "#     api_key=api_key,\n",
    "#     temperature=0,\n",
    "#     response_format=\"json\"  # structured output mode\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a822908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000249A517FD70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "# from ollama_deep_researcher.configuration import Configuration, SearchAPI\n",
    "# from ollama_deep_researcher.utils import deduplicate_and_format_sources, tavily_search, format_sources, perplexity_search, duckduckgo_search, searxng_search, strip_thinking_tokens, get_config_value\n",
    "# from ollama_deep_researcher.state import SummaryState, SummaryStateInput, SummaryStateOutput\n",
    "# from ollama_deep_researcher.prompts import query_writer_instructions, summarizer_instructions, reflection_instructions, get_current_date\n",
    "# from ollama_deep_researcher.lmstudio import ChatLMStudio\n",
    "\n",
    "# Nodes\n",
    "def generate_query(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that generates a search query based on the research topic.\n",
    "    \n",
    "    Uses an LLM to create an optimized search query for web research based on\n",
    "    the user's research topic. Supports both LMStudio and Ollama as LLM providers.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the research topic\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated query\n",
    "    \"\"\"\n",
    "    print(\"---------<Generate Queries>--------------\")\n",
    "    # Format the prompt\n",
    "    current_date = get_current_date()\n",
    "    formatted_prompt = query_writer_instructions.format(\n",
    "        current_date=current_date,\n",
    "        research_topic=state.research_topic\n",
    "    )\n",
    "\n",
    "    # Generate a query\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    # Choose the appropriate LLM based on the provider\n",
    "    llm_json_mode = ChatOllama(\n",
    "        base_url=configurable.ollama_base_url, \n",
    "        model=configurable.local_llm, \n",
    "        temperature=0, \n",
    "        format=\"json\"\n",
    "        )\n",
    "    \n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=formatted_prompt),\n",
    "        HumanMessage(content=f\"Generate a query for web search:\")]\n",
    "    )\n",
    "    \n",
    "    # Get the content\n",
    "    content = result.content\n",
    "\n",
    "    # Parse the JSON response and get the query\n",
    "    try:\n",
    "        query = json.loads(content)\n",
    "        search_query = query['query']\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        # If parsing fails or the key is not found, use a fallback query\n",
    "        if configurable.strip_thinking_tokens:\n",
    "            content = strip_thinking_tokens(content)\n",
    "        search_query = content\n",
    "    print(f\">>> Search Query: {search_query}\")\n",
    "    return {\"search_query\": search_query}\n",
    "\n",
    "def web_research(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that performs web research using the generated search query.\n",
    "    \n",
    "    Executes a web search using the configured search API (tavily, perplexity, \n",
    "    duckduckgo, or searxng) and formats the results for further processing.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the search query and research loop count\n",
    "        config: Configuration for the runnable, including search API settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including sources_gathered, research_loop_count, and web_research_results\n",
    "    \"\"\"\n",
    "    print(\"---------<Web Research>--------------\")\n",
    "    # Configure\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "\n",
    "    # Get the search API\n",
    "    search_api = get_config_value(configurable.search_api)\n",
    "\n",
    "    # Search the web\n",
    "    if search_api == \"tavily\":\n",
    "        search_results = tavily_search(state.search_query, fetch_full_page=configurable.fetch_full_page, max_results=1)\n",
    "        search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, fetch_full_page=configurable.fetch_full_page)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported search API: {configurable.search_api}\")\n",
    "    \n",
    "    print(f\">>> web_research_results: {search_str}\")\n",
    "    return {\"sources_gathered\": [format_sources(search_results)], \"research_loop_count\": state.research_loop_count + 1, \"web_research_results\": [search_str]}\n",
    "\n",
    "def summarize_sources(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that summarizes web research results.\n",
    "    \n",
    "    Uses an LLM to create or update a running summary based on the newest web research \n",
    "    results, integrating them with any existing summary.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing research topic, running summary,\n",
    "              and web research results\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including running_summary key containing the updated summary\n",
    "    \"\"\"\n",
    "    print(\"---------<Summarize Sources>--------------\")\n",
    "    # Existing summary\n",
    "    existing_summary = state.running_summary\n",
    "\n",
    "    # Most recent web research\n",
    "    most_recent_web_research = state.web_research_results[-1]\n",
    "\n",
    "    # Build the human message\n",
    "    if existing_summary:\n",
    "        human_message_content = (\n",
    "            f\"<Existing Summary> \\n {existing_summary} \\n <Existing Summary>\\n\\n\"\n",
    "            f\"<New Context> \\n {most_recent_web_research} \\n <New Context>\"\n",
    "            f\"Update the Existing Summary with the New Context on this topic: \\n <User Input> \\n {state.research_topic} \\n <User Input>\\n\\n\"\n",
    "        )\n",
    "    else:\n",
    "        human_message_content = (\n",
    "            f\"<Context> \\n {most_recent_web_research} \\n <Context>\"\n",
    "            f\"Create a Summary using the Context on this topic: \\n <User Input> \\n {state.research_topic} \\n <User Input>\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # Run the LLM\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    # Choose the appropriate LLM based on the provider\n",
    "    llm = ChatOllama(\n",
    "        base_url=configurable.ollama_base_url, \n",
    "        model=configurable.local_llm, \n",
    "        temperature=0\n",
    "        )\n",
    "    \n",
    "    result = llm.invoke(\n",
    "        [SystemMessage(content=summarizer_instructions),\n",
    "        HumanMessage(content=human_message_content)]\n",
    "    )\n",
    "\n",
    "    # Strip thinking tokens if configured\n",
    "    running_summary = result.content\n",
    "    if configurable.strip_thinking_tokens:\n",
    "        running_summary = strip_thinking_tokens(running_summary)\n",
    "\n",
    "    print(f\">>> running_summary: {running_summary}\")\n",
    "    return {\"running_summary\": running_summary}\n",
    "\n",
    "def reflect_on_summary(state: SummaryState, config: RunnableConfig):\n",
    "    \"\"\"LangGraph node that identifies knowledge gaps and generates follow-up queries.\n",
    "    \n",
    "    Analyzes the current summary to identify areas for further research and generates\n",
    "    a new search query to address those gaps. Uses structured output to extract\n",
    "    the follow-up query in JSON format.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and research topic\n",
    "        config: Configuration for the runnable, including LLM provider settings\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including search_query key containing the generated follow-up query\n",
    "    \"\"\"\n",
    "    print(\"---------<Reflect on Summary>--------------\")\n",
    "    # Generate a query\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    \n",
    "    # Choose the appropriate LLM based on the provider\n",
    "    llm_json_mode = ChatOllama(\n",
    "        base_url=configurable.ollama_base_url, \n",
    "        model=configurable.local_llm, \n",
    "        temperature=0, \n",
    "        format=\"json\"\n",
    "        )\n",
    "    \n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=reflection_instructions.format(research_topic=state.research_topic)),\n",
    "        HumanMessage(content=f\"Reflect on our existing knowledge: \\n === \\n {state.running_summary}, \\n === \\n And now identify a knowledge gap and generate a follow-up web search query:\")]\n",
    "    )\n",
    "    \n",
    "    # Strip thinking tokens if configured\n",
    "    try:\n",
    "        # Try to parse as JSON first\n",
    "        reflection_content = json.loads(result.content)\n",
    "        # Get the follow-up query\n",
    "        query = reflection_content.get('follow_up_query')\n",
    "        # Check if query is None or empty\n",
    "        if not query:\n",
    "            # Use a fallback query\n",
    "            return {\"search_query\": f\"Tell me more about {state.research_topic}\"}\n",
    "        print(f\">>> Not Query_search_query: {query}\")\n",
    "        return {\"search_query\": query}\n",
    "    except (json.JSONDecodeError, KeyError, AttributeError):\n",
    "        # If parsing fails or the key is not found, use a fallback query\n",
    "        print(f\"Tell me more about {state.research_topic}\")\n",
    "        return {\"search_query\": f\"Tell me more about {state.research_topic}\"}\n",
    "        \n",
    "def finalize_summary(state: SummaryState):\n",
    "    \"\"\"LangGraph node that finalizes the research summary.\n",
    "    \n",
    "    Prepares the final output by deduplicating and formatting sources, then\n",
    "    combining them with the running summary to create a well-structured\n",
    "    research report with proper citations.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the running summary and sources gathered\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with state update, including running_summary key containing the formatted final summary with sources\n",
    "    \"\"\"\n",
    "    print(\"---------<Finalize Summary>--------------\")\n",
    "    # Deduplicate sources before joining\n",
    "    seen_sources = set()\n",
    "    unique_sources = []\n",
    "    \n",
    "    for source in state.sources_gathered:\n",
    "        # Split the source into lines and process each individually\n",
    "        for line in source.split('\\n'):\n",
    "            # Only process non-empty lines\n",
    "            if line.strip() and line not in seen_sources:\n",
    "                seen_sources.add(line)\n",
    "                unique_sources.append(line)\n",
    "    \n",
    "    # Join the deduplicated sources\n",
    "    all_sources = \"\\n\".join(unique_sources)\n",
    "    state.running_summary = f\"## Summary\\n{state.running_summary}\\n\\n ### Sources:\\n{all_sources}\"\n",
    "    print(f\">>> running_summary: {state.running_summary}\")\n",
    "    return {\"running_summary\": state.running_summary}\n",
    "\n",
    "def route_research(state: SummaryState, config: RunnableConfig) -> Literal[\"finalize_summary\", \"web_research\"]:\n",
    "    \"\"\"LangGraph routing function that determines the next step in the research flow.\n",
    "    \n",
    "    Controls the research loop by deciding whether to continue gathering information\n",
    "    or to finalize the summary based on the configured maximum number of research loops.\n",
    "    \n",
    "    Args:\n",
    "        state: Current graph state containing the research loop count\n",
    "        config: Configuration for the runnable, including max_web_research_loops setting\n",
    "        \n",
    "    Returns:\n",
    "        String literal indicating the next node to visit (\"web_research\" or \"finalize_summary\")\n",
    "    \"\"\"\n",
    "    print(\"---------<Route Research>--------------\")\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    if state.research_loop_count <= configurable.max_web_research_loops:\n",
    "        print(\">>>Routing to web research\")\n",
    "        return \"web_research\"\n",
    "    else:\n",
    "        print(\">>> Routing to web finalize_summary\")\n",
    "        return \"finalize_summary\"\n",
    "\n",
    "# Add nodes and edges\n",
    "builder = StateGraph(SummaryState, input=SummaryStateInput, output=SummaryStateOutput, config_schema=Configuration)\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "builder.add_node(\"summarize_sources\", summarize_sources)\n",
    "builder.add_node(\"reflect_on_summary\", reflect_on_summary)\n",
    "builder.add_node(\"finalize_summary\", finalize_summary)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_edge(\"generate_query\", \"web_research\")\n",
    "builder.add_edge(\"web_research\", \"summarize_sources\")\n",
    "builder.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n",
    "builder.add_conditional_edges(\"reflect_on_summary\", route_research)\n",
    "builder.add_edge(\"finalize_summary\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573d285",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84940def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------<Generate Queries>--------------\n",
      ">>> Search Query: 한화오션 기업 동향 2025\n",
      "Node 'generate_query':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source: 한화오션 주가 분석 2025: 기업개요부터 재무·투자지표까지 완벽 정리\n",
      "===\n",
      "URL: https://jung-defi.tistory.com/entry/한화오션-주가-분석-2025-기업개요부터-재무·투자지표까지-완벽-정리\n",
      "===\n",
      "Most relevant content from source: 외국인 투자자 지분율: 약 2530% (2025년 2월 기준 7,500만~9,000만 주 추정). ▶ CB(전환사채) 영향: 2023년 발행 2.3조 원 규모 CB(전환가 4만 350원)가 주가 74,300원으로 상승하며 전환 가속화 가능성. ▶ 외국인 순매수: 2025년 2월 순매수 2위(1,185억 원) 기록 후 3월 추가 매수로 주가 급등 견인. ▶ 매출액: 약 10조 7,000억 원 (+45%). ▶ 수주 모멘텀: 2024년 카타르 LNG선 12척(약 33억 달러) 포함 누적 수주액 증가. ▶ 외부 환경: 환율 상승(1,350원/USD 추정), 글로벌 친환경 선박 수요 증가, 미국 방산 시장 진출이 가치 상승 촉진. ▶ 리스크: 단기 주가 과열(2025년 1월 50% 상승 후 조정 가능성), CB(전환사채) 2.3조 원 물량(전환가 4만 350원) 전환 시 주식 희석 우려. ▶ PER: 2023년: 33.15배. 단기 (20일): 2025년 1월 6일 이평선 타고 가파른 상승(5만 1,000원 기록).\n",
      "===\n",
      "Full source content limited to 1000 tokens: Published Time: 2025-03-03T18:13:04+09:00\n",
      "한화오션 주가 분석 2025: 기업개요부터 재무·투자지표까지 완벽 정리\n",
      "본문 바로가기\n",
      "Finance\n",
      "검색\n",
      "\n",
      "\n",
      "관리\n",
      "글쓰기\n",
      "로그인\n",
      "로그아웃\n",
      "\n",
      "메뉴\n",
      "\n",
      "홈\n",
      "태그\n",
      "방명록\n",
      "\n",
      "카테고리 없음\n",
      "한화오션 주가 분석 2025: 기업개요부터 재무·투자지표까지 완벽 정리\n",
      "by 정론 2025. 3. 3.\n",
      "반응형\n",
      "오늘은 한화오션 주가를 중심으로 기업개요, 재무분석, 투자지표, 업종 분석까지 2025년 전망을 포함해 자세히 살펴보겠습니다. 조선업과 방산을 아우르는 한화오션의 성장 가능성을 체크해 보세요!\n",
      "\n",
      "한화오션 주가 분석\n",
      "1. 한화오션 기업개요: 조선업의 새로운 강자\n",
      "한화오션은 한화그룹 계열사로, 과거 대우조선해양에서 2023년 5월 한화에 인수되며 새롭게 태어났습니다.\n",
      "경남 거제에 본사를 두고 있으며, LNG 운반선, 구축함, 해양 플랜트 등 다양한 분야에서 활동합니다.\n",
      "한화그룹의 자본력을 바탕으로 적자 구조를 개선하며, 미국 해군 MRO 사업과 친환경 선박 개발로 주목받는 기업입니다.\n",
      "한화오션은 상선(60%), 특수선(20%), 해양(20%) 비중(추정)을 기반으로 운영되며, 2025년 매출 12조 6,948억 원, 영업이익 7,365억 원을 목표로 합니다.\n",
      "특히 LNG선, FPSO, 잠수함 등 고부가가치 제품 중심으로 사업 포트폴리오를 재편하며, 한화그룹의 자금 및 기술 지원을 통해 글로벌 조선·해양 시장에서 입지를 넓히고 있습니다.\n",
      "1) 주요 사업:\n",
      "▶ 상선(LNG선, 컨테이너선) :상선 부문은 한화오션의 매출에서 가장 큰 비중을 차지하는 핵심 사업으로, 다양한 상업용 선박을 설계하고 건조합니다. 이 부문은 글로벌 물류와 에너지 수송需求에 따라 성장하며, 특히 친환경 선박 기술에 주력하고 있습니다.\n",
      "▶ 특수선(방산 함정) :특수선 부문은 방산 중심으로, 군함 및 특수 목적 선박을 건조하며 안정적인 수익 기반을 제공합니다. 한화오션은 이 부문을 2030년까지 매출 4배(8,500억 원 → 2조 9,000억 원)로 키우겠다는 목표를 세웠습니다.\n",
      "▶ 해양(FPSO 등) :해양 부문은 오일·가스 탐사 및 생산을 위한 해양 구조물 건조를 담당하며, 최근 수익성 개선과 신사업 확장으로 주목받고 있습니다.\n",
      "2) 한화오션 주주 현황 (2025년 3월 기준 추정)\n",
      "▶ 주식 발행 및 유통 정보\n",
      "\n",
      "상장 주식 수: 약 3억 571만 주 (2023년 유상증자 포함 총 발행 주식 수 기준).\n",
      "시가총액: 주가 74,300원 기준 약 22조 7,000억 원.\n",
      "유통 주식 비율: 약 70% 이상 (CB 전환 및 기관·외국인 보유 반영 추정).\n",
      "\n",
      "▶ 주요 주주 구성\n",
      "한화오션의 주주 구조는 한화그룹 인수 이후 최대주주 및 특수관계인 중심으로 안정화되었으며, 기관 및 외국인 투자자 비중도 상당합니다.\n",
      "▶ 최대주주 및 특수관계인\n",
      "\n",
      "한화에어로스페이스 외 특수관계인: 약 35.41% (2023년 12월 기준). 한화그룹 계열사(한화에어로스페이스, 한화시스템 등)와 김승연 회장 일가 포함.\n",
      "국민연금공단 지분율: 약 8.5% (2024년 9월 기준 2,600만 주 보유 추정). 조선업 회복과 방산 수주 기대감으로 지분 유지 및 일부 매수 지속.\n",
      "외국인 투자자 지분율: 약 2530% (2025년 2월 기준 7,500만~9,000만 주 추정). 2025년 2월 매도(55만 주) 후 3월 초 재매수(최근 급등 요인).  트럼프 당선 후 미 해군 MRO 사업 연계로 외국인 러브콜 증가.\n",
      "\n",
      "3) 주주 변동 내역\n",
      "\n",
      "2023년: 한화그룹 인수 후 유상증자(9,000억 원 + 2조 6,000억 원)로 최대주주 지분 강화.\n",
      "2024년: 국민연금과 외국인 지분 증가, CB(전환사채) 일부 전환(전환가 4만 350원)으로 유통 주식 수 확대.\n",
      "2025년 1~2월: 외국인·기관 매도 후 3월 수주(잠수함 배치-II, FPSO 등) 소식으로 매수 급증.\n",
      "\n",
      "4) 특이 사항\n",
      "▶ CB(전환사채) 영향: 2023년 발행 2.3조 원 규모 CB(전환가 4만 350원)가 주가 74,300원으로 상승하며 전환 가속화 가능성. 최대 5,300만 주 추가 발행 가능, 주식 희석 우려 존재.\n",
      "▶ 외국인 순매수: 2025년 2월 순매수 2위(1,185억 원) 기록 후 3월 추가 매수로 주가 급등 견인.\n",
      "\n",
      "2. 한화오션 재무분석: 실적 개선과 2025 전망\n",
      "한화오션의 재무 상태는 과거 적자에서 점차 회복 중입니다.\n",
      "2023년 실적:\n",
      "▶ 매출액: 7조 4,083억 원 (+52.4%).\n",
      "▶ 영업이익: -1,965억 원 (적자 축소).\n",
      "▶ 부채비율: 223% (2022년 1,542%에서 대폭 개선).\n",
      "2024년 추정:\n",
      "▶ 매출액: 약 10조 7,000억 원 (+45%).\n",
      "▶ 영업이익: 약 2,380억 원 (흑자 전환).\n",
      "2025년 전망:\n",
      "▶ 매출액: 12조 6,948억 원 (+17.8%).\n",
      "▶ 영업이익: 7,365억 원 (+209.6%, OPM 5.8%).\n",
      "▶ 이유: LNG선 수주 확대와 고환율 기조 지속.\n",
      "투자 포인트: 재무구조 개선과 흑자 전환은 한화오션 주가 상승의 핵심 동력입니다.\n",
      "과거 부실을 털어내며 안정성을 높이고 있죠.\n",
      "투자 지형이 바뀐다…날아오른 한화, 숨 고르는 현대차 그룹주 ETF에 희비 엇갈려…한화 60%, 포스코 20% 상승 현대차 ETF는 트럼프 리스크에 '아쉬운 성적표' 국내 증시가 올 들어 상승 흐름을 보이는 가운데 그룹주 ETF(상장지수펀드) 간에 희비가 엇갈리 n.news.naver.com\n",
      "주요 가치 변화 요인\n",
      "▶ 수익성 개선: 적자 컨테이너선 비중 감소, 고수익 LNG선 매출 증가로 OPM(영업이익률)이 2023년 -2.7%에서 2025년 5.8%로 개선 전망.\n",
      "▶ 수주 모멘텀: 2024년 카타르 LNG선 12척(약 33억 달러) 포함 누적 수주액 증가. 2025년 해양 부문 수주 기대감 상승.\n",
      "▶ 외부 환경: 환율 상승(1,350원/USD 추정), 글로벌 친환경 선박 수요 증가, 미국 방산 시장 진출이 가치 상승 촉진.\n",
      "▶ 리스크: 단기 주가 과열(2025년 1월 50% 상승 후 조정 가능성), CB(전환사채) 2.3조 원 물량(전환가 4만 350원) 전환 시 주식 희석 우려.\n",
      "\n",
      "3. 한화오션 투자지표: 지금 사도 될까?\n",
      "한화오션 주가는 2025년 2월 말 기준 약 7만 원대까지 올라왔습니다.\n",
      "주요 투자지표를 통해 평가해 보겠습니다.\n",
      "▶ PER: 2023년: 33.15배. 2025년 예상: 19.69배 (수익성 개선).\n",
      "▶ PBR: 약 2.01배 (고평가 논란 있음).\n",
      "▶ ROE: 2025년 9.64% 예상 (성장 가능성).\n",
      "▶ 주가 흐름: 52주 최고 81,000원, 최저 22,500원.\n",
      "\n",
      "한화오셔주가차트\n",
      "기술적 지표\n",
      "▶ 이동평균선 (MA):\n",
      "\n",
      "단기 (20일): 2025년 1월 6일 이평선 타고 가파른 상승(5만 1,000원 기록).\n",
      "이후 하락 시 4만 5,000원 지지선 테스트 가능.\n",
      "장기 (200일): 3만 8,000원대 유지 중. 상승 추세 지속 시 강한 지지.\n",
      "\n",
      "▶ RSI (상대강도지수):\n",
      "\n",
      "1월 과매수(70 초과) → 2월 조정 후 50~60 수준 추정.\n",
      "중립 구간에서 안정화 중.\n",
      "\n",
      "▶ 지지·저항선:\n",
      "\n",
      "지지: 4만 원 (심리적 지지 + 200일선 근접).\n",
      "저항: 5만 원 (단기 고점), 5만 7,000원 (SK증권 목표주가 근접).\n",
      "\n",
      "▶ 차트 패턴\n",
      "\n",
      "상승삼각형: 2024년 하반기 점진적 고점 상승 후 2025년 초 돌파. 이후 과열로 단기 하락 패턴 관찰.\n",
      "조정 국면: 2월 외국인 매도(55만 주) 및 기관 매도(37만 주)로 단기 하락.  3월 중 실적 발표 및 수주 소식에 따라 반등 가능성.\n",
      "\n",
      "분석: 현재 주가는 다소 높게 평가되지만, LNG선 수주와 방산 성장으로 중장기 전망은 밝습니다.\n",
      "단기 변동성에 주의하세요!\n",
      "\n",
      "4. 조선업과 방산 업종 분석: 한화오션의 위치\n",
      "한화오션은 조선업과 방산업을 동시에 다룹니다.\n",
      "업종 동향을 통해 주가 영향을 알아봅시다\n",
      "조선업:\n",
      "▶ 수요: LNG선, 친환경 선박 수요 증가.\n",
      "▶ 경쟁: HD한국조선해양, 삼성중공업 대비 방산 비중 높아 안정성 우위.\n",
      "▶ 전망: 2025년 상선 정체, LNG선과 해양 플랜트 성장 기대.\n",
      "방산:\n",
      "▶ 국내: KDDX, 울산급 수주 가능성.\n",
      "▶ 해외: 미 ... [truncated]\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "**Summary of Recent Trends for Hyundai Ocean (Hyundai Ocean):**  \n",
      "\n",
      "Hyundai Ocean, a leading player in shipbuilding and defense, has seen its stock rise to around 70,000 won as of late 2025, driven by strong performance in LNG ship orders, defense sector growth, and favorable external factors. Key highlights include:  \n",
      "\n",
      "1. **Stock Performance & Technical Indicators:**  \n",
      "   - The stock reached a 52-week high of 81,000 won but has since stabilized, with technical indicators suggesting a potential correction. The 20-day moving average (51,000 won) and 200-day moving average (38,000 won) provide support, while the RSI is expected to stabilize in the 50–60 range after a 2025 February overbought phase.  \n",
      "\n",
      "2. **Key Drivers of Growth:**  \n",
      "   - **LNG Ship Orders:** The company secured 12 LNG ships (worth ~33 billion USD) for Qatar in 2024, with growing demand for eco-friendly vessels.  \n",
      "   - **Defense Sector Expansion:** Strong domestic orders for KDDX and potential overseas contracts in the U.S. defense market are boosting confidence.  \n",
      "   - **External Factors:** Currency appreciation (1,350 won/USD) and rising global demand for green ships are enhancing value.  \n",
      "\n",
      "3. **Industry Position:**  \n",
      "   - **Shipbuilding:** Competes effectively with Hyundai Heavy Industries and Samsung Heavy Industries, with a focus on LNG and marine plant projects.  \n",
      "   - **Defense:** Dominates the domestic market with KDDX and UlSAN projects, while overseas opportunities in the U.S. military sector offer growth potential.  \n",
      "\n",
      "4. **Risks & Challenges:**  \n",
      "   - **Overvaluation:** A high PBR (2.01x) and elevated PER (19.69x in 2025) raise concerns about market pricing.  \n",
      "   - **Convertible Bonds:** The 2.3 trillion won convertible bonds (conversion price: 43,500 won) could dilute shares if converted.  \n",
      "   - **Short-Term Volatility:** February 2025 saw foreign and institutional selling, but March rebounded following new orders and results.  \n",
      "\n",
      "**Conclusion:** While Hyundai Ocean’s stock is currently overvalued, its long-term growth potential in LNG and defense sectors, coupled with favorable macroeconomic conditions, make it a compelling investment. Investors should monitor technical corrections and the conversion of bonds, while focusing on the company’s strategic positioning in key industries.\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      ">>> Not Query_search_query: What are typical performance benchmarks and metrics used to evaluate [specific technology]?\n",
      "---------<Route Research>--------------\n",
      ">>>Routing to web research\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source: IT Benchmarking: A Tool for Measuring IT Performance - Splunk\n",
      "===\n",
      "URL: https://www.splunk.com/en_us/blog/learn/it-benchmarking.html\n",
      "===\n",
      "Most relevant content from source: IT benchmarking highlights specific areas where peers have made progress or where the organization has overlooked opportunities for improvement. It provides quantitative and explicit standards for comparison. IT benchmarking centers on data, offering IT teams standardized measures that simplify comparison and help plan incremental improvements.\n",
      "===\n",
      "Full source content limited to 1000 tokens: IT Benchmarking: A Tool for Measuring IT Performance\n",
      "\n",
      "In the quest to demonstrate value to top management and other stakeholders or convince them to act, the IT leadership may assess the current state of IT. This assessment covers various dimensions including:\n",
      "\n",
      "These assessments measure, analyze, and understand the status, behavior and performance across IT dimensions. They highlight well-performing areas and identify gaps or concerns that require improvement. By comparing with expectations, IT functions gain better insight into their current position and determine what needs enhancing to get to the next level.\n",
      "\n",
      "In this article, we will discuss the definition of IT benchmarking, the two main approaches, and the benefits and drawbacks of this method of asses the state of an organizations IT performance.\n",
      "\n",
      "What is IT benchmarking?\n",
      "\n",
      "IT benchmarking is a popular method for assessing the current state of IT across various parameters. Gartner defines benchmarking as the comparison between an organization’s performance and the performance of designated organizations or indexes.\n",
      "\n",
      "Indexes refer to publicly (or privately) available indicators for a factor that is associated with a measurement element such as:\n",
      "\n",
      "IT benchmarking involves measuring the performance of an organization’s IT products, services, or practices against those of a similar organization, usually an industry competitor or peer. By benchmarking against a superior organization, an IT team can identify improvement initiatives that could propel them to the top of the class.\n",
      "\n",
      "(Related reading: IT service management).\n",
      "\n",
      "The ITIL 4 Direct Plan and Improve publication states that benchmarking serves as a valuable tool for motivating culture change, based on the premise that organizations can set the standard by which others measure themselves.\n",
      "\n",
      "IT benchmarking approaches\n",
      "\n",
      "Where should IT organizations start with benchmarking? Context matters here. IT organizations can use two fundamental types of benchmarking: internal and external benchmarking.\n",
      "\n",
      "Internal IT benchmarking\n",
      "\n",
      "Internal IT benchmarking compares performance within an organization, usually between departments or functions that may or may not carry out similar activities.\n",
      "\n",
      "For example, a product team might compare its development metrics, such as on-time delivery and team velocity, with those of other internal product teams. Knowledge bodies like APQC provide IT benchmarking measures that IT functions can use as starting points to gain insights into the efficiency and effectiveness of their processes.\n",
      "\n",
      "Examples of such measures include:\n",
      "\n",
      "External IT benchmarking\n",
      "\n",
      "External IT benchmarking compares an organization’s performance with industry peers using data from various sources, including third party sources or standards. An organization, regulators, industry associations, or contracted third parties may carry out external benchmarking. Ideally, companies share anonymized data to use for benchmarking.\n",
      "\n",
      "Examples of external IT benchmarking services include:\n",
      "\n",
      "Gartner offers a benchmarking service called IT Score for CIOs that covers 30 functional activities across 7 functional objectives. Organizations can perform a self-assessment to measure their maturity level relative to Gartner’s best practice research and prioritize improvement areas.\n",
      "\n",
      "\n",
      "\n",
      "Gartner IT Score for CIOs\n",
      "\n",
      "IDC Global through its research arm provides an IT benchmarking service that generates insights based on six key parameters that are analyzed as follows:\n",
      "\n",
      "Info~Tech Research Group provides an IT spend and staffing benchmarking service that involves a comparative analysis of IT’s financial and human resource data with aggregate data from industry participants. The analyzed information is then presented based on stakeholder views showing insights and opportunities, and thereafter a cost and staffing optimization plan is provided. The example below shows sample outputs of the benchmarking analysis.\n",
      "\n",
      "\n",
      "\n",
      "Sample IT Benchmarking Analysis (Source: Info~Tech)\n",
      "\n",
      "IT benc... [truncated]\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "The new context provided discusses **IT benchmarking** as a method for evaluating an organization's IT performance against industry peers or internal departments. However, this topic is unrelated to the recent trends of **Hyundai Ocean** (한화오션), which focuses on its stock performance, business operations, and industry position in the shipping and logistics sector. \n",
      "\n",
      "Since the new context does not provide any direct or indirect information about Hyundai Ocean's business, financial health, or strategic initiatives, it is **not relevant** to the existing summary. Therefore, the existing summary remains unchanged and is not updated with the new context. \n",
      "\n",
      "**Final Note:** The user's query about \"recent trends for Hyundai Ocean\" does not align with the topic of IT benchmarking, which is a separate domain. The existing summary should remain focused on Hyundai Ocean's stock, industry position, and related factors.\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      "---------<Route Research>--------------\n",
      ">>>Routing to web research\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source: 한화오션 기업분석 - 2025년 지금 꼭 주목해야 할 조선·방산 융합 기업\n",
      "===\n",
      "URL: https://stelline.tistory.com/entry/한화오션-기업분석-–-2025년-지금-꼭-주목해야-할-조선·방산-융합-기업\n",
      "===\n",
      "Most relevant content from source: 목차민수 조선사를 넘어 방산 플랫폼 기업으로한화오션의 사업 구조 - 세 가지 수익 축6개월 실적 데이터로 본 턴어라운드 흐름최근 한 달 간의 주요 뉴스와 의미조선·방산 산업 내 경쟁 포지션은?글로벌 진출 전략과 수출 확대 방향재무건전성 회복과 수익성 흐름2025년 한화오션을 바라보는 시선 1\n",
      "===\n",
      "Full source content limited to 1000 tokens: 기업을 읽는 사람\n",
      "\n",
      "한화오션 기업분석 – 2025년 지금 꼭 주목해야 할 조선·방산 융합 기업\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "목차\n",
      "\n",
      "\n",
      "\n",
      "1. 민수 조선사를 넘어 방산 플랫폼 기업으로\n",
      "\n",
      "한화오션은 2023년 대우조선해양이 한화그룹에 인수되며 탄생한 조선·방산 융합 기업입니다. 단순히 이름만 바뀐 것이 아니라 기업의 사업 방향 자체가 달라졌습니다. 기존의 민수 조선 중심에서 벗어나, 방위산업 중심의 첨단 조선 기술 기업으로 전환 중입니다.\n",
      "\n",
      "거제 옥포조선소를 중심으로 LNG운반선, 초대형 유조선, 컨테이너선 등 상선을 제작하고 있으며 동시에 장보고-III형 잠수함, 대형 수송함, 구축함 등 특수선(군용함정) 생산에 집중하고 있습니다. 최근에는 AI 기반 스마트십, 자율운항 무인함정 개발에도 적극 나서며 미래 기술에 대한 투자도 강화하고 있습니다.\n",
      "\n",
      "→ 핵심 정리: 민수 조선소에서 해양 방산 기술 기업으로의 변신이 본격화되고 있다.\n",
      "\n",
      "\n",
      "\n",
      "2. 한화오션의 사업 구조 – 세 가지 수익 축\n",
      "\n",
      "한화오션의 사업 구조는 크게 세 가지 축으로 나눌 수 있습니다. 첫째, LNG선과 컨테이너선 등을 포함하는 상선 부문으로 전체 매출의 약 60% 이상을 차지합니다.\n",
      "\n",
      "둘째, 해군 함정과 잠수함을 포함하는 특수선 부문으로, 2024년 기준 약 17%까지 매출 비중이 증가하며 빠르게 성장하고 있습니다.\n",
      "\n",
      "셋째는 자율운항, AI 스마트십, 친환경 조선 솔루션 등 기술 중심의 미래 사업입니다. 이 부문은 현재 매출 비중은 낮지만 성장 속도가 가장 빠르며, 장기적인 수익 모델로 주목받고 있습니다.\n",
      "\n",
      "→ 핵심 정리: 기존 상선 중심 구조에서 방산과 기술 부문이 빠르게 성장 중이다.\n",
      "\n",
      "3. 재무제표 분석 – 수치로 보는 한화오션의 체력\n",
      "\n",
      "2024년 말 기준 한화오션의 연매출은 약 9조 2천억 원이며, 영업이익은 3,500억 원을 기록했습니다. 순이익은 약 2,450억 원으로, 3년 만의 흑자 전환을 달성한 해로 기록됩니다. 영업이익률은 약 3.8%, 순이익률은 2.6% 수준으로, 조선업 특성상 낮은 이익률 구조임에도 불구하고 수익성이 뚜렷하게 회복된 모습입니다.\n",
      "\n",
      "자산총계는 약 18조 원이며, 부채총계는 약 10조 원으로 부채비율은 약 180% 수준입니다. 이는 2022년 대비 절반 수준으로 떨어진 수치이며, 그룹 편입 후 자본금 확충과 차입금 상환이 동시에 진행되었기 때문입니다.\n",
      "\n",
      "현금흐름도 개선되었습니다. 2024년에는 영업활동현금흐름이 약 3,200억 원 규모로 플러스로 전환되었으며, 이는 수주산업 특성상 ‘선수금 기반 실현 가능성’이 높아졌다는 것을 의미합니다.\n",
      "\n",
      "ROE(자기자본이익률)는 6.5%, ROA(총자산수익률)는 3.2% 수준으로, 조선업 평균보다 높은 수준입니다. 이 수치는 수주 중심 사업 구조에서 기술 기반 고부가 부문이 차지하는 비중이 늘어난 데 따른 결과입니다.\n",
      "\n",
      "→ 핵심 정리: 한화오션은 2024년 재무구조를 안정화하고 수익성과 현금흐름까지 회복한 상태다.\n",
      "\n",
      "4. 경쟁사 대비 한화오션의 차별화 전략은?\n",
      "\n",
      "한화오션은 조선업계에서 현대중공업, 삼성중공업과 함께 ‘빅3’로 분류되지는 않지만, 그들과 뚜렷하게 구분되는 전략을 취하고 있습니다.\n",
      "\n",
      "현대·삼성이 민수 대형 선박(컨테이너선, 유조선) 중심으로 스케일 확대에 집중하는 반면, 한화오션은 ‘고부가 특수선’과 ‘방산기술’에 초점을 맞춘 포지셔닝을 구축했습니다.\n",
      "\n",
      "특히 장보고-III형 잠수함 시리즈와 AI 기반 전투 플랫폼, 무인 수상정(MUSV), 스마트십 플랫폼 등은 국내에서 유일하게 한화오션만 개발 및 생산이 가능한 기술들입니다. 이로 인해 단가 경쟁에서 벗어나 기술 경쟁력 기반의 고마진 구조 확보가 가능합니다.\n",
      "\n",
      "또한 방산 계열사들과의 시너지를 통해 원가절감, 통합기술 확보, 수출 계약 공동 접근 등 다양한 통합 전략이 가능한 것도 큰 장점입니다. 예를 들어 한화디펜스는 육상 무기, 한화시스템은 통신·센서 분야를 담당하며, 한화오션은 해양플랫폼을 통합하는 구조입니다. 이런 수직계열화는 현대·삼성과는 완전히 다른 방향의 성장 전략이라 할 수 있습니다.\n",
      "\n",
      "무엇보다도 조선소 내부에 디지털 트윈 기반의 스마트 생산 설비가 본격 도입되고 있어, 동일한 선박을 더 빠르고 정밀하게 제조할 수 있는 ‘속도와 품질’에서의 우위까지 확보하고 있습니다.\n",
      "\n",
      "→ 핵심 정리: 한화오션은 방산 중심 고부가 전략과 그룹 시너지를 통해 현대·삼성과 완전히 다른 방향의 경쟁 우위를 구축하고 있다.\n",
      "\n",
      "5. 조선·방산 산업 내 경쟁 포지션은?\n",
      "\n",
      "조선 부문에서는 현대중공업, 삼성중공업 등과 경쟁하고 있으며, 특히 한화오션은 LNG선 분야에서 독립형 화물창(IMO Type B) 기술을 세계 최초로 상용화해 기술적 차별화를 이루고 있습니다.\n",
      "\n",
      "방산 부문에서는 한국 해군의 주력 잠수함 제조사이며, 무인 전투체계, 자율운항 솔루션 등 고기술 방산 플랫폼을 보유한 기업으로 분류됩니다. 조선사 중 방산 기술을 직접 보유한 사례는 한화오션이 유일합니다.\n",
      "\n",
      "→ 핵심 정리: LNG선 기술과 해군 방산 기술력 모두에서 국내 유일무이한 경쟁력을 갖췄다.\n",
      "\n",
      "6. 글로벌 진출 전략과 수출 확대 방향\n",
      "\n",
      "한화오션은 동남아시아, 중동 등 신흥시장을 대상으로 해군 장비 수출을 추진하고 있으며, AI·스마트십 솔루션을 앞세워 북미와 유럽 시장 진출도 병행하고 있습니다.\n",
      "\n",
      "LNG선의 경우, 노르웨이·그리스·일본 등 주요 선사들과 계약을 논의 중이며, 향후 기술 수출(SaaS 형태의 플랫폼 판매)까지 계획하고 있습니다. 기술 기반 조선사로서의 포지션이 글로벌 고객에게 통하고 있는 단계입니다.\n",
      "\n",
      "→ 핵심 정리: 기술력 중심의 수출 전략이 성과로 연결되는 구간에 진입했다.\n",
      "\n",
      "7. 재무건전성 회복과 수익성 흐름\n",
      "\n",
      "한화그룹 편입 이후 약 1조 원 규모의 유상증자가 단행되었고, 부채비율은 180% 수준으로 안정화되었습니다. 영업활동현금흐름도 플러스로 전환되며, 고정비 부담이 줄어드는 구조로 재편 중입니다.\n",
      "\n",
      "ROE(자기자본이익률)는 6.5% 수준까지 회복됐고, 이는 업계 평균을 상회하는 수준입니다. 수주잔고 기반의 안정적 외형 확대 속에서, 이익률까지 동반 개선되고 있다는 점은 주목할 만합니다.\n",
      "\n",
      "→ 핵심 정리: 실적뿐만 아니라, 재무 구조도 확실히 정상화되고 있다.\n",
      "\n",
      "8. 정리하며 – 2025년 한화오션을 바라보는 시선\n",
      "\n",
      "한화오션은 지금 민수 조선, 방산 수출, AI기반 스마트십이라는 세 가지 축을 동시에 강화하고 있는 기업입니다. 국내에서 유일하게 해군 잠수함을 건조하면서 무인 전투 플랫폼까지 개발하고 있는 기업이며, 글로벌 시장에서도 기술 기반 조선사로 인정받기 시작했습니다.\n",
      "\n",
      "2025년은 이 변화가 ‘성과’로 드러나는 시점이며, 단순 조선주로 평가하던 시선에서 벗어나 방산·기술 융합 기업으로 재평가받을 시기입니다.\n",
      "\n",
      "→ 핵심 정리: 한화오션은 2025년, 진정한 의미의 구조적 성장주로 탈바꿈한 기업이다.\n",
      "\n",
      "https://naver.me/GFBqb2WE\n",
      "\n",
      "한화오션 기업분석 & 투자가이드 – 조선과 방산의 융합, 구조적 반등의 시그널\n",
      "\n",
      "민수 조선사를 넘어 방산 플랫폼 기업으로 한화오션의 사업 구조 – 세 가지 수익 축 6개월 실적 데이터로 본 턴어라운드 흐름 최근 한 달 간의 주요 뉴스와 의미 조선·방산 산업 내 경쟁 포지션\n",
      "\n",
      "contents.premium.naver.com\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'기업분석' 카테고리의 다른 글\n",
      "\n",
      "[LG생활건강 기업 분석] 다시 도약을 준비하는 뷰티·헬스케어 리더!(2) | 2025.04.28\n",
      "[LG전자 기업 분석] 미래 시장을 향한 전략적 변화를 읽다(2) | 2025.04.27\n",
      "팔란티어 테크놀로지스 기업 분석 - 데이터 기반 혁신 기업의 미래를 읽다.(0) | 2025.04.27\n",
      "현대자동차 기업분석 – 전기차, 수소차, 그리고 미래를 향한 대전환(2) | 2025.04.27\n",
      "SK하이닉스 기업분석 – HBM으로 반등한 반도체 핵심주, 주가와 실적까지 읽는다(2) | 2025.04.25\n",
      "태그\n",
      "\n",
      "관련글\n",
      "\n",
      "댓글0\n",
      "\n",
      "공지사항\n",
      "\n",
      "최근글\n",
      "\n",
      "인기글\n",
      "\n",
      "최근댓글\n",
      "\n",
      "TEL. 02.1234.5678 / 경기 성남시 분당구 판교역로\n",
      "\n",
      "© Kakao Corp.\n",
      "\n",
      "티스토리툴바\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "**한화오션 기업분석 & 투자가이드 – 최근 동향 및 전망**  \n",
      "한화오션은 최근 **민수 조선, 방산 수출, AI 기반 스마트십**이라는 세 가지 축을 동시에 강화하며, 국내 유일의 해군 잠수함 건조 기업으로 성장하고 있습니다. 2025년을 맞이해 **구조적 반등**을 이끌어내는 기업으로 재평가되고 있으며, 기술 기반 조선사로서의 글로벌 인지도가 높아지고 있습니다.  \n",
      "\n",
      "### **1. 최근 주요 동향**  \n",
      "- **세 가지 수익 축 강화**:  \n",
      "  - **민수 조선**: 노르웨이, 그리스, 일본 등 주요 선사와 LNG선 계약 논의 중이며, 기술 수출(SaaS 플랫폼 판매)을 통해 수익 모델 다각화.  \n",
      "  - **방산 수출**: 국내 유일의 해군 잠수함 건조 기업으로, 무인 전투 플랫폼 개발을 통해 방산 분야에서 차별화된 경쟁력 확보.  \n",
      "  - **AI 기반 스마트십**: 스마트십 기술을 기반으로 한 글로벌 시장 진출(유럽, 미국)을 추진하며, 기술 기반 조선사로서의 포지션 강화.  \n",
      "\n",
      "- **재무 건전성 회복**:  \n",
      "  - 한화그룹 편입 후 **1조 원 규모의 주식 발행**을 통해 자금 확보, **부채 비율 180% 안정**.  \n",
      "  - **운영 현금흐름 긍정화** 및 **고정비 부담 감소**로 재무 구조 개선.  \n",
      "  - **ROE 6.5%** 달성, 산업 평균을 상회하며 투자자 신뢰 확보.  \n",
      "\n",
      "- **글로벌 시장 확장**:  \n",
      "  - LNG선 기술을 통한 **기술 수출**을 통해 해외 시장 진출, SaaS 플랫폼을 통한 추가 수익 창출.  \n",
      "  - **AI·스마트 기술**을 기반으로 한 해상 운송 솔루션 개발로 글로벌 경쟁력 강화.  \n",
      "\n",
      "### **2. 시장 경쟁력**  \n",
      "- **국내 유일의 방산 기술 기업**: 해군 잠수함 건조 및 무인 전투 플랫폼 개발을 통해 **방산 분야에서의 독보적 경쟁력** 확보.  \n",
      "- **기술 기반 조선사로서의 인지도**: 스마트십 기술과 AI 통합을 통해 **글로벌 시장에서의 신뢰도** 상승.  \n",
      "- **다각화된 수익 모델**: LNG선, 방산, 스마트 기술 분야에서 **다양한 수익원 확보**로 리스크 분산.  \n",
      "\n",
      "### **3. 2025년 전망**  \n",
      "- **구조적 반등**을 이끌어내는 **방산·기술 통합형 기업**으로 재평가.  \n",
      "- **글로벌 시장 확장**과 **기술 수출**을 통해 **재무 건전성과 수익성**을 동시에 강화.  \n",
      "- **AI·스마트 기술**을 기반으로 한 **해상 운송 솔루션**을 통해 **새로운 수익 창출** 기회 확보.  \n",
      "\n",
      "### **결론**  \n",
      "한화오션은 **민수 조선, 방산, 스마트 기술**이라는 세 가지 축을 통해 **구조적 반등**을 이끌어내고 있으며, 기술 기반 조선사로서의 글로벌 인지도와 재무 건전성 향상으로 **2025년을 맞이한 기업 가치 상승**을 기대할 수 있습니다. 특히, **방산 기술과 AI 통합**을 통한 차별화된 경쟁력 확보는 향후 성장의 핵심 동력이 될 전망입니다.\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      ">>> Not Query_search_query: What are typical performance benchmarks and metrics used to evaluate [specific technology]?\n",
      "---------<Route Research>--------------\n",
      ">>>Routing to web research\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Web Research>--------------\n",
      ">>> web_research_results: Sources:\n",
      "\n",
      "Source: IT Benchmarking: A Tool for Measuring IT Performance - Splunk\n",
      "===\n",
      "URL: https://www.splunk.com/en_us/blog/learn/it-benchmarking.html\n",
      "===\n",
      "Most relevant content from source: IT benchmarking highlights specific areas where peers have made progress or where the organization has overlooked opportunities for improvement. It provides quantitative and explicit standards for comparison. IT benchmarking centers on data, offering IT teams standardized measures that simplify comparison and help plan incremental improvements.\n",
      "===\n",
      "Full source content limited to 1000 tokens: IT Benchmarking: A Tool for Measuring IT Performance\n",
      "\n",
      "In the quest to demonstrate value to top management and other stakeholders or convince them to act, the IT leadership may assess the current state of IT. This assessment covers various dimensions including:\n",
      "\n",
      "These assessments measure, analyze, and understand the status, behavior and performance across IT dimensions. They highlight well-performing areas and identify gaps or concerns that require improvement. By comparing with expectations, IT functions gain better insight into their current position and determine what needs enhancing to get to the next level.\n",
      "\n",
      "In this article, we will discuss the definition of IT benchmarking, the two main approaches, and the benefits and drawbacks of this method of asses the state of an organizations IT performance.\n",
      "\n",
      "What is IT benchmarking?\n",
      "\n",
      "IT benchmarking is a popular method for assessing the current state of IT across various parameters. Gartner defines benchmarking as the comparison between an organization’s performance and the performance of designated organizations or indexes.\n",
      "\n",
      "Indexes refer to publicly (or privately) available indicators for a factor that is associated with a measurement element such as:\n",
      "\n",
      "IT benchmarking involves measuring the performance of an organization’s IT products, services, or practices against those of a similar organization, usually an industry competitor or peer. By benchmarking against a superior organization, an IT team can identify improvement initiatives that could propel them to the top of the class.\n",
      "\n",
      "(Related reading: IT service management).\n",
      "\n",
      "The ITIL 4 Direct Plan and Improve publication states that benchmarking serves as a valuable tool for motivating culture change, based on the premise that organizations can set the standard by which others measure themselves.\n",
      "\n",
      "IT benchmarking approaches\n",
      "\n",
      "Where should IT organizations start with benchmarking? Context matters here. IT organizations can use two fundamental types of benchmarking: internal and external benchmarking.\n",
      "\n",
      "Internal IT benchmarking\n",
      "\n",
      "Internal IT benchmarking compares performance within an organization, usually between departments or functions that may or may not carry out similar activities.\n",
      "\n",
      "For example, a product team might compare its development metrics, such as on-time delivery and team velocity, with those of other internal product teams. Knowledge bodies like APQC provide IT benchmarking measures that IT functions can use as starting points to gain insights into the efficiency and effectiveness of their processes.\n",
      "\n",
      "Examples of such measures include:\n",
      "\n",
      "External IT benchmarking\n",
      "\n",
      "External IT benchmarking compares an organization’s performance with industry peers using data from various sources, including third party sources or standards. An organization, regulators, industry associations, or contracted third parties may carry out external benchmarking. Ideally, companies share anonymized data to use for benchmarking.\n",
      "\n",
      "Examples of external IT benchmarking services include:\n",
      "\n",
      "Gartner offers a benchmarking service called IT Score for CIOs that covers 30 functional activities across 7 functional objectives. Organizations can perform a self-assessment to measure their maturity level relative to Gartner’s best practice research and prioritize improvement areas.\n",
      "\n",
      "\n",
      "\n",
      "Gartner IT Score for CIOs\n",
      "\n",
      "IDC Global through its research arm provides an IT benchmarking service that generates insights based on six key parameters that are analyzed as follows:\n",
      "\n",
      "Info~Tech Research Group provides an IT spend and staffing benchmarking service that involves a comparative analysis of IT’s financial and human resource data with aggregate data from industry participants. The analyzed information is then presented based on stakeholder views showing insights and opportunities, and thereafter a cost and staffing optimization plan is provided. The example below shows sample outputs of the benchmarking analysis.\n",
      "\n",
      "\n",
      "\n",
      "Sample IT Benchmarking Analysis (Source: Info~Tech)\n",
      "\n",
      "IT benc... [truncated]\n",
      "Node 'web_research':\n",
      "'\\n---\\n'\n",
      "---------<Summarize Sources>--------------\n",
      ">>> running_summary: \n",
      "\n",
      "**Updated Summary: Recent Hanwha Ocean Corporate Trends**  \n",
      "\n",
      "Hanwha Ocean has been actively advancing its strategic initiatives in three key areas: **civil shipbuilding**, **defense exports**, and **AI-driven smart shipping**. These efforts are supported by a strong focus on technological innovation and operational efficiency. In addition to these core business areas, the company is increasingly leveraging **IT benchmarking** as a strategic tool to evaluate and optimize its IT infrastructure, ensuring alignment with industry standards and best practices.  \n",
      "\n",
      "**1. Civil Shipbuilding and Defense Exports**  \n",
      "Hanwha Ocean continues to strengthen its position in the global shipbuilding and defense markets by delivering high-quality, customized solutions. The company is investing in advanced manufacturing technologies and digital tools to enhance productivity and reduce costs. This includes integrating AI and automation into production processes, which aligns with its broader goal of becoming a leader in smart manufacturing.  \n",
      "\n",
      "**2. AI-Driven Smart Shipping**  \n",
      "A major focus of Hanwha Ocean’s innovation strategy is the development of **AI-based smart shipping solutions**. These include predictive maintenance systems, autonomous vessel technologies, and data-driven logistics platforms. By adopting cutting-edge IT systems, the company aims to improve operational efficiency, reduce environmental impact, and meet the growing demand for sustainable maritime solutions.  \n",
      "\n",
      "**3. IT Benchmarking for Strategic Alignment**  \n",
      "To ensure its IT capabilities support these technological advancements, Hanwha Ocean is adopting **IT benchmarking** as a key performance management practice. This involves comparing its IT performance—such as data management, cybersecurity, and digital transformation initiatives—with industry peers and best practices. By using quantitative standards and anonymized data from external sources (e.g., Gartner’s IT Score or Info~Tech’s benchmarking services), the company identifies gaps in its IT infrastructure and prioritizes improvements.  \n",
      "\n",
      "**4. Internal and External Benchmarking**  \n",
      "Hanwha Ocean is also conducting **internal IT benchmarking** to evaluate the efficiency of its departments, such as IT operations, cybersecurity, and digital project management. This helps the company optimize resource allocation and streamline processes. Additionally, **external benchmarking** with industry leaders in shipbuilding and technology allows Hanwha Ocean to stay competitive and adapt to evolving market demands.  \n",
      "\n",
      "**Conclusion**  \n",
      "By integrating IT benchmarking into its strategic framework, Hanwha Ocean is ensuring that its technological investments—particularly in AI and smart shipping—are aligned with global standards. This approach not only enhances operational efficiency but also positions the company as a forward-thinking leader in the maritime and defense sectors.\n",
      "Node 'summarize_sources':\n",
      "'\\n---\\n'\n",
      "---------<Reflect on Summary>--------------\n",
      ">>> Not Query_search_query: What specific IT benchmarking tools or platforms does Hanwha Ocean use, such as Gartner’s IT Score or Info~Tech’s services, and how are they integrated into their strategic planning processes?\n",
      "---------<Route Research>--------------\n",
      ">>> Routing to web finalize_summary\n",
      "Node 'reflect_on_summary':\n",
      "'\\n---\\n'\n",
      "---------<Finalize Summary>--------------\n",
      ">>> running_summary: ## Summary\n",
      "\n",
      "\n",
      "**Updated Summary: Recent Hanwha Ocean Corporate Trends**  \n",
      "\n",
      "Hanwha Ocean has been actively advancing its strategic initiatives in three key areas: **civil shipbuilding**, **defense exports**, and **AI-driven smart shipping**. These efforts are supported by a strong focus on technological innovation and operational efficiency. In addition to these core business areas, the company is increasingly leveraging **IT benchmarking** as a strategic tool to evaluate and optimize its IT infrastructure, ensuring alignment with industry standards and best practices.  \n",
      "\n",
      "**1. Civil Shipbuilding and Defense Exports**  \n",
      "Hanwha Ocean continues to strengthen its position in the global shipbuilding and defense markets by delivering high-quality, customized solutions. The company is investing in advanced manufacturing technologies and digital tools to enhance productivity and reduce costs. This includes integrating AI and automation into production processes, which aligns with its broader goal of becoming a leader in smart manufacturing.  \n",
      "\n",
      "**2. AI-Driven Smart Shipping**  \n",
      "A major focus of Hanwha Ocean’s innovation strategy is the development of **AI-based smart shipping solutions**. These include predictive maintenance systems, autonomous vessel technologies, and data-driven logistics platforms. By adopting cutting-edge IT systems, the company aims to improve operational efficiency, reduce environmental impact, and meet the growing demand for sustainable maritime solutions.  \n",
      "\n",
      "**3. IT Benchmarking for Strategic Alignment**  \n",
      "To ensure its IT capabilities support these technological advancements, Hanwha Ocean is adopting **IT benchmarking** as a key performance management practice. This involves comparing its IT performance—such as data management, cybersecurity, and digital transformation initiatives—with industry peers and best practices. By using quantitative standards and anonymized data from external sources (e.g., Gartner’s IT Score or Info~Tech’s benchmarking services), the company identifies gaps in its IT infrastructure and prioritizes improvements.  \n",
      "\n",
      "**4. Internal and External Benchmarking**  \n",
      "Hanwha Ocean is also conducting **internal IT benchmarking** to evaluate the efficiency of its departments, such as IT operations, cybersecurity, and digital project management. This helps the company optimize resource allocation and streamline processes. Additionally, **external benchmarking** with industry leaders in shipbuilding and technology allows Hanwha Ocean to stay competitive and adapt to evolving market demands.  \n",
      "\n",
      "**Conclusion**  \n",
      "By integrating IT benchmarking into its strategic framework, Hanwha Ocean is ensuring that its technological investments—particularly in AI and smart shipping—are aligned with global standards. This approach not only enhances operational efficiency but also positions the company as a forward-thinking leader in the maritime and defense sectors.\n",
      "\n",
      " ### Sources:\n",
      "* 한화오션 주가 분석 2025: 기업개요부터 재무·투자지표까지 완벽 정리 : https://jung-defi.tistory.com/entry/한화오션-주가-분석-2025-기업개요부터-재무·투자지표까지-완벽-정리\n",
      "* IT Benchmarking: A Tool for Measuring IT Performance - Splunk : https://www.splunk.com/en_us/blog/learn/it-benchmarking.html\n",
      "* 한화오션 기업분석 - 2025년 지금 꼭 주목해야 할 조선·방산 융합 기업 : https://stelline.tistory.com/entry/한화오션-기업분석-–-2025년-지금-꼭-주목해야-할-조선·방산-융합-기업\n",
      "Node 'finalize_summary':\n",
      "'\\n---\\n'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m     pprint.pprint(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Final generation\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# pprint.pprint(value['keys']['documents'])\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m pprint.pprint(\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkeys\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mgeneration\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'keys'"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "import pprint\n",
    "\n",
    "inputs = {\"research_topic\": \"최근 한화오션 기업 동향\"}\n",
    "for output in graph.stream(input=inputs):\n",
    "    # print(output)\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        print(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "# pprint.pprint(value['keys']['documents'])\n",
    "pprint.pprint(value['keys']['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13197919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(value['keys']['generation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
